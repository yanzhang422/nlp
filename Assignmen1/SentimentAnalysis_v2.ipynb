{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the datasets file which downloaded from Dr.Julian McAuley's website http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "reviews = []\n",
    "labels = []\n",
    "with open('Musical_Instruments_5.json', 'r') as fr:\n",
    "    lines = fr.readlines()\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    tmp_line = eval(line)\n",
    "    score = float(tmp_line['overall'])\n",
    "    text = tmp_line['reviewText']\n",
    "    reviews.append(text)\n",
    "    ## discretize them into 3 sentiment categories (0:negative, 1:neutral, 2:positive)\n",
    "    #label =0\n",
    "#     if score>=5.0:\n",
    "#         label = 2\n",
    "#     elif score>=4.0:\n",
    "#         label = 1\n",
    "#     else:\n",
    "#         label = 0\n",
    "    labels.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current labels for text {1.0, 2.0, 3.0, 4.0, 5.0}\n"
     ]
    }
   ],
   "source": [
    "print('current labels for text',set(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the field \"reviewText\"¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the symbol, digital numbers\n",
    "def preprocess(reviews):\n",
    "    word_list = reviews.split(' ')\n",
    "    new_word_list = []\n",
    "    for word in word_list:\n",
    "        if word.isalpha():\n",
    "            new_word_list.append(word)\n",
    "    return ' '.join(new_word_list)\n",
    "\n",
    "for i  in range(len(reviews)):\n",
    "    reviews[i] = preprocess(reviews[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "##from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text,is_lower=False,remove_stopwords=False,stem_words=False):\n",
    "    # Clean the text, with the option to remove stopwords and to stem/lemmate words.\n",
    "    if is_lower:\n",
    "        text = [w.lower() for w in text.strip().split()]#lower the words\n",
    "    else:\n",
    "        text = [w for w in text.strip().split()]\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "\n",
    "    text = \" \".join(text)\n",
    "     # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    # Optionally, shorten words to their stemmer/lemmatization\n",
    "    # Compare the result between stemming and lemmatization, the lemmatization find the orginal form of the word \n",
    "    # better than using stemming, eg, \"despite\" trans to \"despit\" in stemming, to \"despite\" in lemmatization\n",
    "    # to much shorten in stemmer\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        ##stemmer = SnowballStemmer('english')\n",
    "        stemmer = WordNetLemmatizer()\n",
    "        ##stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        stemmed_words = [stemmer.lemmatize(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "\n",
    "    # Return a list of words\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal text: --------------- Not much to write about but it does exactly what supposed filters out the pop now my recordings are much more it is one of the lowest prices pop filters on amazon so might as well buy they honestly work the same despite their\n",
      "processed text --------------- much write exactly supposed filter pop recording much one lowest price pop filter amazon might well buy honestly work despite\n"
     ]
    }
   ],
   "source": [
    "print('orginal text:','-'*15,reviews[0])\n",
    "for i  in range(len(reviews)):\n",
    "    reviews[i] = text_to_wordlist(reviews[i],is_lower=True,remove_stopwords=True,stem_words=True)\n",
    "print('processed text','-'*15,reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset in a training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installation\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from pandas import DataFrame as df\n",
    "import pandas as pd\n",
    "train_x, test_x, train_y, test_y = train_test_split(reviews, labels,train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the sentiment analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "### Extraction the feature, categorizing and tagging words use ngram and tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After preprocessing, using sklearn to process the text feature. Normally using Bag of Words model to count the frequence of the word, N-gram model to observe the frequence in a particular sequence,Word2vec model represents word in vector. Using the TfidfVectorizer to convert the text to vector according to the term frequence, and using ngram_range from CountVectorizer for N-grams chocing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "#Filter words that appear in sentences that exceed max_df/lower than min_df\n",
    "#Allow max two consistent word to be combined as a new feature, because we analyse feature as word vector\n",
    "#Remove the terms that appear in less than 1% of the documents\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,2),min_df=0.01) \n",
    "def extract_tfidf_(reviews,is_train=True):\n",
    "    if is_train:\n",
    "        tfidf_matrix = tfidf_vec.fit_transform(reviews)\n",
    "    else:\n",
    "        tfidf_matrix = tfidf_vec.transform(reviews)\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = extract_tfidf_(train_x,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9234, 601), 9234)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf.shape,len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = extract_tfidf_(test_x,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1027, 601), 1027)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf.shape,len(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction more text features for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from sklearn.decomposition import PCA,NMF\n",
    "#base statistics features for length\n",
    "def extract_base_features(reviews,is_words=False,is_chars=False):\n",
    "    if is_chars:\n",
    "        _features = [len(''.join(set(str(line).replace(' ', '')))) for line in reviews]\n",
    "    if is_words:\n",
    "        _features = [len(str(line)) for line in reviews]\n",
    "    return np.array(_features).reshape(-1,1)\n",
    "#Reduce dimensional features\n",
    "#Tfidf is typically a sparse matrix, which doesn’t support all the usual matrix or array operations\n",
    "#Nmf is a non-negative matrix factorization that can be obtained as a positive statistics feature to dense format\n",
    "#NMF can't set default number of topics, so add manually for it, there is only one file (music instrument) input\n",
    "no_topics = 1\n",
    "nmf=NMF(n_components=no_topics,random_state=1)\n",
    "def extract_nmf_features(tf_idfs,is_train=True):\n",
    "    if is_train:\n",
    "        nmf.fit(tf_idfs)\n",
    "    return nmf.transform(tf_idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nmf = extract_nmf_features(train_tfidf,True)\n",
    "test_nmf = extract_nmf_features(test_tfidf,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = extract_base_features(train_x,is_words=True)\n",
    "train_chars = extract_base_features(train_x,is_chars=True)\n",
    "test_words = extract_base_features(test_x,is_words=True)\n",
    "test_chars = extract_base_features(test_x,is_chars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.hstack([train_tfidf.toarray(),train_nmf,train_words,train_chars])\n",
    "test_features = np.hstack([test_tfidf.toarray(),test_nmf,test_words,test_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9234, 604) (1027, 604)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape,test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % topic_idx)\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "guitar string sound one like good great work use pedal\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "tfidf_feature_names = tfidf_vec.get_feature_names()\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection by random forest, random forest is one of the feature-based classifiers, it easy to understand and avoid over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['fea_{%s}'%(str(i)) for i in range(train_features.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 604/604 [00:44<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0.011', 'fea_{595}'), ('0.010', 'fea_{214}'), ('0.008', 'fea_{142}'), ('0.007', 'fea_{350}'), ('0.006', 'fea_{202}'), ('0.006', 'fea_{127}'), ('0.005', 'fea_{602}'), ('0.005', 'fea_{297}'), ('0.005', 'fea_{235}'), ('0.004', 'fea_{84}'), ('0.004', 'fea_{115}'), ('0.003', 'fea_{216}'), ('0.003', 'fea_{213}'), ('0.002', 'fea_{76}'), ('0.002', 'fea_{603}'), ('0.002', 'fea_{544}'), ('0.002', 'fea_{502}'), ('0.002', 'fea_{497}'), ('0.002', 'fea_{38}'), ('0.002', 'fea_{35}'), ('0.002', 'fea_{211}'), ('0.002', 'fea_{149}'), ('0.001', 'fea_{80}'), ('0.001', 'fea_{7}'), ('0.001', 'fea_{60}'), ('0.001', 'fea_{559}'), ('0.001', 'fea_{555}'), ('0.001', 'fea_{51}'), ('0.001', 'fea_{479}'), ('0.001', 'fea_{399}'), ('0.001', 'fea_{379}'), ('0.001', 'fea_{375}'), ('0.001', 'fea_{372}'), ('0.001', 'fea_{369}'), ('0.001', 'fea_{34}'), ('0.001', 'fea_{283}'), ('0.001', 'fea_{22}'), ('0.001', 'fea_{229}'), ('0.001', 'fea_{197}'), ('0.001', 'fea_{181}'), ('0.000', 'fea_{79}'), ('0.000', 'fea_{591}'), ('0.000', 'fea_{589}'), ('0.000', 'fea_{584}'), ('0.000', 'fea_{580}'), ('0.000', 'fea_{528}'), ('0.000', 'fea_{522}'), ('0.000', 'fea_{485}'), ('0.000', 'fea_{473}'), ('0.000', 'fea_{398}'), ('0.000', 'fea_{384}'), ('0.000', 'fea_{373}'), ('0.000', 'fea_{320}'), ('0.000', 'fea_{305}'), ('0.000', 'fea_{239}'), ('0.000', 'fea_{210}'), ('0.000', 'fea_{174}'), ('0.000', 'fea_{171}'), ('0.000', 'fea_{163}'), ('0.000', 'fea_{161}'), ('0.000', 'fea_{133}'), ('0.000', 'fea_{117}'), ('-0.010', 'fea_{395}'), ('-0.009', 'fea_{31}'), ('-0.009', 'fea_{301}'), ('-0.009', 'fea_{246}'), ('-0.009', 'fea_{165}'), ('-0.009', 'fea_{12}'), ('-0.008', 'fea_{487}'), ('-0.008', 'fea_{295}'), ('-0.008', 'fea_{131}'), ('-0.007', 'fea_{597}'), ('-0.007', 'fea_{592}'), ('-0.007', 'fea_{423}'), ('-0.007', 'fea_{410}'), ('-0.007', 'fea_{377}'), ('-0.007', 'fea_{36}'), ('-0.007', 'fea_{321}'), ('-0.007', 'fea_{245}'), ('-0.007', 'fea_{234}'), ('-0.007', 'fea_{218}'), ('-0.007', 'fea_{168}'), ('-0.007', 'fea_{166}'), ('-0.007', 'fea_{158}'), ('-0.006', 'fea_{90}'), ('-0.006', 'fea_{64}'), ('-0.006', 'fea_{578}'), ('-0.006', 'fea_{576}'), ('-0.006', 'fea_{566}'), ('-0.006', 'fea_{551}'), ('-0.006', 'fea_{541}'), ('-0.006', 'fea_{538}'), ('-0.006', 'fea_{526}'), ('-0.006', 'fea_{488}'), ('-0.006', 'fea_{460}'), ('-0.006', 'fea_{447}'), ('-0.006', 'fea_{434}'), ('-0.006', 'fea_{345}'), ('-0.006', 'fea_{338}'), ('-0.006', 'fea_{325}'), ('-0.006', 'fea_{292}'), ('-0.006', 'fea_{26}'), ('-0.006', 'fea_{244}'), ('-0.006', 'fea_{242}'), ('-0.006', 'fea_{193}'), ('-0.006', 'fea_{185}'), ('-0.006', 'fea_{154}'), ('-0.006', 'fea_{14}'), ('-0.006', 'fea_{147}'), ('-0.006', 'fea_{134}'), ('-0.005', 'fea_{86}'), ('-0.005', 'fea_{82}'), ('-0.005', 'fea_{73}'), ('-0.005', 'fea_{66}'), ('-0.005', 'fea_{598}'), ('-0.005', 'fea_{574}'), ('-0.005', 'fea_{546}'), ('-0.005', 'fea_{536}'), ('-0.005', 'fea_{519}'), ('-0.005', 'fea_{518}'), ('-0.005', 'fea_{500}'), ('-0.005', 'fea_{483}'), ('-0.005', 'fea_{475}'), ('-0.005', 'fea_{467}'), ('-0.005', 'fea_{465}'), ('-0.005', 'fea_{459}'), ('-0.005', 'fea_{455}'), ('-0.005', 'fea_{454}'), ('-0.005', 'fea_{440}'), ('-0.005', 'fea_{42}'), ('-0.005', 'fea_{382}'), ('-0.005', 'fea_{381}'), ('-0.005', 'fea_{380}'), ('-0.005', 'fea_{367}'), ('-0.005', 'fea_{364}'), ('-0.005', 'fea_{348}'), ('-0.005', 'fea_{328}'), ('-0.005', 'fea_{324}'), ('-0.005', 'fea_{315}'), ('-0.005', 'fea_{313}'), ('-0.005', 'fea_{311}'), ('-0.005', 'fea_{306}'), ('-0.005', 'fea_{304}'), ('-0.005', 'fea_{294}'), ('-0.005', 'fea_{284}'), ('-0.005', 'fea_{280}'), ('-0.005', 'fea_{274}'), ('-0.005', 'fea_{266}'), ('-0.005', 'fea_{264}'), ('-0.005', 'fea_{258}'), ('-0.005', 'fea_{240}'), ('-0.005', 'fea_{222}'), ('-0.005', 'fea_{20}'), ('-0.005', 'fea_{19}'), ('-0.005', 'fea_{18}'), ('-0.005', 'fea_{177}'), ('-0.005', 'fea_{167}'), ('-0.005', 'fea_{159}'), ('-0.005', 'fea_{13}'), ('-0.005', 'fea_{122}'), ('-0.005', 'fea_{108}'), ('-0.004', 'fea_{94}'), ('-0.004', 'fea_{88}'), ('-0.004', 'fea_{78}'), ('-0.004', 'fea_{74}'), ('-0.004', 'fea_{71}'), ('-0.004', 'fea_{68}'), ('-0.004', 'fea_{58}'), ('-0.004', 'fea_{587}'), ('-0.004', 'fea_{569}'), ('-0.004', 'fea_{552}'), ('-0.004', 'fea_{54}'), ('-0.004', 'fea_{53}'), ('-0.004', 'fea_{537}'), ('-0.004', 'fea_{533}'), ('-0.004', 'fea_{527}'), ('-0.004', 'fea_{521}'), ('-0.004', 'fea_{509}'), ('-0.004', 'fea_{503}'), ('-0.004', 'fea_{501}'), ('-0.004', 'fea_{495}'), ('-0.004', 'fea_{489}'), ('-0.004', 'fea_{486}'), ('-0.004', 'fea_{482}'), ('-0.004', 'fea_{476}'), ('-0.004', 'fea_{470}'), ('-0.004', 'fea_{453}'), ('-0.004', 'fea_{445}'), ('-0.004', 'fea_{430}'), ('-0.004', 'fea_{418}'), ('-0.004', 'fea_{417}'), ('-0.004', 'fea_{414}'), ('-0.004', 'fea_{40}'), ('-0.004', 'fea_{402}'), ('-0.004', 'fea_{393}'), ('-0.004', 'fea_{391}'), ('-0.004', 'fea_{370}'), ('-0.004', 'fea_{356}'), ('-0.004', 'fea_{355}'), ('-0.004', 'fea_{352}'), ('-0.004', 'fea_{344}'), ('-0.004', 'fea_{335}'), ('-0.004', 'fea_{334}'), ('-0.004', 'fea_{314}'), ('-0.004', 'fea_{307}'), ('-0.004', 'fea_{300}'), ('-0.004', 'fea_{298}'), ('-0.004', 'fea_{296}'), ('-0.004', 'fea_{281}'), ('-0.004', 'fea_{277}'), ('-0.004', 'fea_{269}'), ('-0.004', 'fea_{263}'), ('-0.004', 'fea_{251}'), ('-0.004', 'fea_{250}'), ('-0.004', 'fea_{248}'), ('-0.004', 'fea_{224}'), ('-0.004', 'fea_{200}'), ('-0.004', 'fea_{1}'), ('-0.004', 'fea_{196}'), ('-0.004', 'fea_{195}'), ('-0.004', 'fea_{179}'), ('-0.004', 'fea_{173}'), ('-0.004', 'fea_{15}'), ('-0.004', 'fea_{130}'), ('-0.004', 'fea_{128}'), ('-0.004', 'fea_{118}'), ('-0.004', 'fea_{104}'), ('-0.003', 'fea_{99}'), ('-0.003', 'fea_{97}'), ('-0.003', 'fea_{92}'), ('-0.003', 'fea_{89}'), ('-0.003', 'fea_{87}'), ('-0.003', 'fea_{85}'), ('-0.003', 'fea_{81}'), ('-0.003', 'fea_{70}'), ('-0.003', 'fea_{6}'), ('-0.003', 'fea_{69}'), ('-0.003', 'fea_{65}'), ('-0.003', 'fea_{601}'), ('-0.003', 'fea_{599}'), ('-0.003', 'fea_{596}'), ('-0.003', 'fea_{585}'), ('-0.003', 'fea_{582}'), ('-0.003', 'fea_{581}'), ('-0.003', 'fea_{57}'), ('-0.003', 'fea_{577}'), ('-0.003', 'fea_{571}'), ('-0.003', 'fea_{565}'), ('-0.003', 'fea_{563}'), ('-0.003', 'fea_{55}'), ('-0.003', 'fea_{558}'), ('-0.003', 'fea_{554}'), ('-0.003', 'fea_{550}'), ('-0.003', 'fea_{548}'), ('-0.003', 'fea_{543}'), ('-0.003', 'fea_{539}'), ('-0.003', 'fea_{535}'), ('-0.003', 'fea_{530}'), ('-0.003', 'fea_{523}'), ('-0.003', 'fea_{513}'), ('-0.003', 'fea_{512}'), ('-0.003', 'fea_{510}'), ('-0.003', 'fea_{50}'), ('-0.003', 'fea_{506}'), ('-0.003', 'fea_{499}'), ('-0.003', 'fea_{498}'), ('-0.003', 'fea_{493}'), ('-0.003', 'fea_{492}'), ('-0.003', 'fea_{491}'), ('-0.003', 'fea_{481}'), ('-0.003', 'fea_{47}'), ('-0.003', 'fea_{478}'), ('-0.003', 'fea_{472}'), ('-0.003', 'fea_{46}'), ('-0.003', 'fea_{469}'), ('-0.003', 'fea_{468}'), ('-0.003', 'fea_{464}'), ('-0.003', 'fea_{463}'), ('-0.003', 'fea_{461}'), ('-0.003', 'fea_{45}'), ('-0.003', 'fea_{451}'), ('-0.003', 'fea_{449}'), ('-0.003', 'fea_{435}'), ('-0.003', 'fea_{431}'), ('-0.003', 'fea_{429}'), ('-0.003', 'fea_{426}'), ('-0.003', 'fea_{425}'), ('-0.003', 'fea_{413}'), ('-0.003', 'fea_{409}'), ('-0.003', 'fea_{39}'), ('-0.003', 'fea_{397}'), ('-0.003', 'fea_{390}'), ('-0.003', 'fea_{387}'), ('-0.003', 'fea_{374}'), ('-0.003', 'fea_{361}'), ('-0.003', 'fea_{359}'), ('-0.003', 'fea_{358}'), ('-0.003', 'fea_{342}'), ('-0.003', 'fea_{333}'), ('-0.003', 'fea_{331}'), ('-0.003', 'fea_{330}'), ('-0.003', 'fea_{327}'), ('-0.003', 'fea_{318}'), ('-0.003', 'fea_{312}'), ('-0.003', 'fea_{308}'), ('-0.003', 'fea_{299}'), ('-0.003', 'fea_{28}'), ('-0.003', 'fea_{289}'), ('-0.003', 'fea_{287}'), ('-0.003', 'fea_{285}'), ('-0.003', 'fea_{278}'), ('-0.003', 'fea_{273}'), ('-0.003', 'fea_{272}'), ('-0.003', 'fea_{270}'), ('-0.003', 'fea_{268}'), ('-0.003', 'fea_{265}'), ('-0.003', 'fea_{261}'), ('-0.003', 'fea_{256}'), ('-0.003', 'fea_{255}'), ('-0.003', 'fea_{238}'), ('-0.003', 'fea_{232}'), ('-0.003', 'fea_{227}'), ('-0.003', 'fea_{226}'), ('-0.003', 'fea_{220}'), ('-0.003', 'fea_{219}'), ('-0.003', 'fea_{215}'), ('-0.003', 'fea_{208}'), ('-0.003', 'fea_{203}'), ('-0.003', 'fea_{198}'), ('-0.003', 'fea_{190}'), ('-0.003', 'fea_{187}'), ('-0.003', 'fea_{182}'), ('-0.003', 'fea_{180}'), ('-0.003', 'fea_{176}'), ('-0.003', 'fea_{175}'), ('-0.003', 'fea_{169}'), ('-0.003', 'fea_{157}'), ('-0.003', 'fea_{155}'), ('-0.003', 'fea_{153}'), ('-0.003', 'fea_{152}'), ('-0.003', 'fea_{151}'), ('-0.003', 'fea_{150}'), ('-0.003', 'fea_{146}'), ('-0.003', 'fea_{141}'), ('-0.003', 'fea_{140}'), ('-0.003', 'fea_{119}'), ('-0.003', 'fea_{116}'), ('-0.003', 'fea_{113}'), ('-0.003', 'fea_{110}'), ('-0.003', 'fea_{105}'), ('-0.003', 'fea_{100}'), ('-0.003', 'fea_{0}'), ('-0.002', 'fea_{91}'), ('-0.002', 'fea_{8}'), ('-0.002', 'fea_{83}'), ('-0.002', 'fea_{75}'), ('-0.002', 'fea_{72}'), ('-0.002', 'fea_{63}'), ('-0.002', 'fea_{61}'), ('-0.002', 'fea_{600}'), ('-0.002', 'fea_{5}'), ('-0.002', 'fea_{59}'), ('-0.002', 'fea_{586}'), ('-0.002', 'fea_{579}'), ('-0.002', 'fea_{573}'), ('-0.002', 'fea_{568}'), ('-0.002', 'fea_{567}'), ('-0.002', 'fea_{562}'), ('-0.002', 'fea_{561}'), ('-0.002', 'fea_{557}'), ('-0.002', 'fea_{556}'), ('-0.002', 'fea_{553}'), ('-0.002', 'fea_{534}'), ('-0.002', 'fea_{532}'), ('-0.002', 'fea_{529}'), ('-0.002', 'fea_{520}'), ('-0.002', 'fea_{515}'), ('-0.002', 'fea_{508}'), ('-0.002', 'fea_{507}'), ('-0.002', 'fea_{4}'), ('-0.002', 'fea_{494}'), ('-0.002', 'fea_{484}'), ('-0.002', 'fea_{480}'), ('-0.002', 'fea_{477}'), ('-0.002', 'fea_{474}'), ('-0.002', 'fea_{466}'), ('-0.002', 'fea_{457}'), ('-0.002', 'fea_{450}'), ('-0.002', 'fea_{44}'), ('-0.002', 'fea_{448}'), ('-0.002', 'fea_{446}'), ('-0.002', 'fea_{442}'), ('-0.002', 'fea_{441}'), ('-0.002', 'fea_{43}'), ('-0.002', 'fea_{439}'), ('-0.002', 'fea_{436}'), ('-0.002', 'fea_{433}'), ('-0.002', 'fea_{432}'), ('-0.002', 'fea_{428}'), ('-0.002', 'fea_{427}'), ('-0.002', 'fea_{424}'), ('-0.002', 'fea_{421}'), ('-0.002', 'fea_{420}'), ('-0.002', 'fea_{41}'), ('-0.002', 'fea_{415}'), ('-0.002', 'fea_{412}'), ('-0.002', 'fea_{411}'), ('-0.002', 'fea_{407}'), ('-0.002', 'fea_{406}'), ('-0.002', 'fea_{3}'), ('-0.002', 'fea_{396}'), ('-0.002', 'fea_{392}'), ('-0.002', 'fea_{386}'), ('-0.002', 'fea_{383}'), ('-0.002', 'fea_{37}'), ('-0.002', 'fea_{368}'), ('-0.002', 'fea_{365}'), ('-0.002', 'fea_{363}'), ('-0.002', 'fea_{362}'), ('-0.002', 'fea_{360}'), ('-0.002', 'fea_{357}'), ('-0.002', 'fea_{347}'), ('-0.002', 'fea_{346}'), ('-0.002', 'fea_{343}'), ('-0.002', 'fea_{341}'), ('-0.002', 'fea_{332}'), ('-0.002', 'fea_{32}'), ('-0.002', 'fea_{329}'), ('-0.002', 'fea_{326}'), ('-0.002', 'fea_{323}'), ('-0.002', 'fea_{322}'), ('-0.002', 'fea_{319}'), ('-0.002', 'fea_{317}'), ('-0.002', 'fea_{310}'), ('-0.002', 'fea_{2}'), ('-0.002', 'fea_{29}'), ('-0.002', 'fea_{291}'), ('-0.002', 'fea_{290}'), ('-0.002', 'fea_{288}'), ('-0.002', 'fea_{282}'), ('-0.002', 'fea_{27}'), ('-0.002', 'fea_{279}'), ('-0.002', 'fea_{276}'), ('-0.002', 'fea_{271}'), ('-0.002', 'fea_{267}'), ('-0.002', 'fea_{25}'), ('-0.002', 'fea_{254}'), ('-0.002', 'fea_{24}'), ('-0.002', 'fea_{249}'), ('-0.002', 'fea_{247}'), ('-0.002', 'fea_{237}'), ('-0.002', 'fea_{236}'), ('-0.002', 'fea_{230}'), ('-0.002', 'fea_{228}'), ('-0.002', 'fea_{221}'), ('-0.002', 'fea_{21}'), ('-0.002', 'fea_{217}'), ('-0.002', 'fea_{207}'), ('-0.002', 'fea_{206}'), ('-0.002', 'fea_{205}'), ('-0.002', 'fea_{204}'), ('-0.002', 'fea_{201}'), ('-0.002', 'fea_{199}'), ('-0.002', 'fea_{194}'), ('-0.002', 'fea_{191}'), ('-0.002', 'fea_{184}'), ('-0.002', 'fea_{183}'), ('-0.002', 'fea_{17}'), ('-0.002', 'fea_{178}'), ('-0.002', 'fea_{172}'), ('-0.002', 'fea_{170}'), ('-0.002', 'fea_{16}'), ('-0.002', 'fea_{164}'), ('-0.002', 'fea_{145}'), ('-0.002', 'fea_{139}'), ('-0.002', 'fea_{138}'), ('-0.002', 'fea_{137}'), ('-0.002', 'fea_{135}'), ('-0.002', 'fea_{126}'), ('-0.002', 'fea_{123}'), ('-0.002', 'fea_{121}'), ('-0.002', 'fea_{112}'), ('-0.002', 'fea_{10}'), ('-0.002', 'fea_{107}'), ('-0.002', 'fea_{102}'), ('-0.001', 'fea_{9}'), ('-0.001', 'fea_{96}'), ('-0.001', 'fea_{95}'), ('-0.001', 'fea_{77}'), ('-0.001', 'fea_{67}'), ('-0.001', 'fea_{62}'), ('-0.001', 'fea_{593}'), ('-0.001', 'fea_{590}'), ('-0.001', 'fea_{583}'), ('-0.001', 'fea_{575}'), ('-0.001', 'fea_{572}'), ('-0.001', 'fea_{570}'), ('-0.001', 'fea_{56}'), ('-0.001', 'fea_{560}'), ('-0.001', 'fea_{549}'), ('-0.001', 'fea_{547}'), ('-0.001', 'fea_{545}'), ('-0.001', 'fea_{542}'), ('-0.001', 'fea_{540}'), ('-0.001', 'fea_{52}'), ('-0.001', 'fea_{517}'), ('-0.001', 'fea_{516}'), ('-0.001', 'fea_{514}'), ('-0.001', 'fea_{511}'), ('-0.001', 'fea_{505}'), ('-0.001', 'fea_{496}'), ('-0.001', 'fea_{490}'), ('-0.001', 'fea_{48}'), ('-0.001', 'fea_{471}'), ('-0.001', 'fea_{462}'), ('-0.001', 'fea_{458}'), ('-0.001', 'fea_{456}'), ('-0.001', 'fea_{452}'), ('-0.001', 'fea_{444}'), ('-0.001', 'fea_{443}'), ('-0.001', 'fea_{437}'), ('-0.001', 'fea_{422}'), ('-0.001', 'fea_{419}'), ('-0.001', 'fea_{416}'), ('-0.001', 'fea_{405}'), ('-0.001', 'fea_{404}'), ('-0.001', 'fea_{401}'), ('-0.001', 'fea_{400}'), ('-0.001', 'fea_{394}'), ('-0.001', 'fea_{388}'), ('-0.001', 'fea_{385}'), ('-0.001', 'fea_{378}'), ('-0.001', 'fea_{371}'), ('-0.001', 'fea_{366}'), ('-0.001', 'fea_{353}'), ('-0.001', 'fea_{351}'), ('-0.001', 'fea_{340}'), ('-0.001', 'fea_{33}'), ('-0.001', 'fea_{339}'), ('-0.001', 'fea_{337}'), ('-0.001', 'fea_{316}'), ('-0.001', 'fea_{303}'), ('-0.001', 'fea_{293}'), ('-0.001', 'fea_{286}'), ('-0.001', 'fea_{275}'), ('-0.001', 'fea_{260}'), ('-0.001', 'fea_{259}'), ('-0.001', 'fea_{257}'), ('-0.001', 'fea_{253}'), ('-0.001', 'fea_{252}'), ('-0.001', 'fea_{241}'), ('-0.001', 'fea_{231}'), ('-0.001', 'fea_{212}'), ('-0.001', 'fea_{209}'), ('-0.001', 'fea_{192}'), ('-0.001', 'fea_{189}'), ('-0.001', 'fea_{188}'), ('-0.001', 'fea_{186}'), ('-0.001', 'fea_{160}'), ('-0.001', 'fea_{156}'), ('-0.001', 'fea_{148}'), ('-0.001', 'fea_{143}'), ('-0.001', 'fea_{136}'), ('-0.001', 'fea_{132}'), ('-0.001', 'fea_{129}'), ('-0.001', 'fea_{125}'), ('-0.001', 'fea_{124}'), ('-0.001', 'fea_{120}'), ('-0.001', 'fea_{11}'), ('-0.001', 'fea_{114}'), ('-0.001', 'fea_{109}'), ('-0.001', 'fea_{106}'), ('-0.001', 'fea_{103}'), ('-0.001', 'fea_{101}'), ('-0.000', 'fea_{98}'), ('-0.000', 'fea_{93}'), ('-0.000', 'fea_{594}'), ('-0.000', 'fea_{588}'), ('-0.000', 'fea_{564}'), ('-0.000', 'fea_{531}'), ('-0.000', 'fea_{525}'), ('-0.000', 'fea_{524}'), ('-0.000', 'fea_{504}'), ('-0.000', 'fea_{49}'), ('-0.000', 'fea_{438}'), ('-0.000', 'fea_{408}'), ('-0.000', 'fea_{403}'), ('-0.000', 'fea_{389}'), ('-0.000', 'fea_{376}'), ('-0.000', 'fea_{354}'), ('-0.000', 'fea_{349}'), ('-0.000', 'fea_{336}'), ('-0.000', 'fea_{30}'), ('-0.000', 'fea_{309}'), ('-0.000', 'fea_{302}'), ('-0.000', 'fea_{262}'), ('-0.000', 'fea_{243}'), ('-0.000', 'fea_{23}'), ('-0.000', 'fea_{233}'), ('-0.000', 'fea_{225}'), ('-0.000', 'fea_{223}'), ('-0.000', 'fea_{162}'), ('-0.000', 'fea_{144}'), ('-0.000', 'fea_{111}')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#select features by rf and training the random forest model\n",
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "#too many depth for the decision tree makes the organization chart complexity\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=4)\n",
    "scores = []\n",
    "for i in tqdm(range(train_features.shape[1])):\n",
    "    score = cross_val_score(rf, train_features[:, i:i+1], train_y, scoring=\"r2\",\n",
    "                            cv=ShuffleSplit(len(train_features), 3, .3))\n",
    "    scores.append((format(np.mean(score), '.3f'), names[i]))\n",
    "print(sorted(scores, reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify text use Naive Bayes Classifiers, because it has better result for text classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()   # Use defaul value to init navie bayes model\n",
    "mnb.fit(train_features,train_y)    # Use training set to fit navie bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6095423563777994"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(test_features, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling high dimension features through tree models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "could not normalize applying tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = [int(line[1][5:-1]) for line in sorted(scores, reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100,max_depth=None,random_state=1123,\n",
    "          n_jobs=13,min_weight_fraction_leaf=0,criterion='gini',\n",
    "          min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set early stop to exit feature selection if it has not grown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number feauture used 10\n",
      "best score: 0.6874391431353457\n",
      "feature used: 10\n",
      "number feauture used 20\n",
      "best score: 0.6932814021421616\n",
      "feature used: 20\n",
      "number feauture used 30\n",
      "number feauture used 40\n",
      "number feauture used 50\n",
      "number feauture used 60\n",
      "number feauture used 70\n",
      "number feauture used 80\n",
      "number feauture used 90\n",
      "number feauture used 100\n",
      "number feauture used 110\n",
      "number feauture used 120\n",
      "exit!\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "num_used = 0\n",
    "its = 0\n",
    "early_stops = 10\n",
    "for num_feas in range(10,len(feature_selected),10):\n",
    "    print('number feauture used',num_feas)\n",
    "    clf.fit(train_features[:,feature_selected[:num_feas]] ,train_y)\n",
    "    cur_score = clf.score(test_features[:,feature_selected[:num_feas]],test_y)\n",
    "    if cur_score>best_score:\n",
    "        num_used = num_feas\n",
    "        best_score = cur_score\n",
    "        print('best score:',best_score)\n",
    "        print('feature used:',num_used)\n",
    "        its=0\n",
    "    else:\n",
    "        its+=1\n",
    "    if its>=early_stops:\n",
    "        print('exit!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Use features derived from a sentiment lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sentiment lexicons which download from public internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {}\n",
    "with open('SentiWordNet.txt', 'r') as fr:\n",
    "    lines = fr.readlines()\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line[0]!='#' and line!='':\n",
    "        word_info = line.split('#')[0].split('\\t')\n",
    "        tmp = {}\n",
    "        tmp['pos'] = word_info[2]\n",
    "        tmp['neg'] = word_info[3]\n",
    "        sentiment_dict[word_info[-1]] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'able': {'pos': '0.125', 'neg': '0'},\n",
       " 'unable': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'dorsal': {'pos': '0', 'neg': '0'},\n",
       " 'ventral': {'pos': '0', 'neg': '0'},\n",
       " 'acroscopic': {'pos': '0', 'neg': '0'},\n",
       " 'basiscopic': {'pos': '0', 'neg': '0'},\n",
       " 'abducting': {'pos': '0', 'neg': '0'},\n",
       " 'adductive': {'pos': '0', 'neg': '0'},\n",
       " 'nascent': {'pos': '0', 'neg': '0'},\n",
       " 'emerging': {'pos': '0', 'neg': '0'},\n",
       " 'dissilient': {'pos': '0.25', 'neg': '0'},\n",
       " 'parturient': {'pos': '0', 'neg': '0'},\n",
       " 'dying': {'pos': '0', 'neg': '0.625'},\n",
       " 'moribund': {'pos': '0', 'neg': '0'},\n",
       " 'last': {'pos': '0', 'neg': '0'},\n",
       " 'abridged': {'pos': '0', 'neg': '0'},\n",
       " 'shortened': {'pos': '0', 'neg': '0'},\n",
       " 'half-length': {'pos': '0.375', 'neg': '0'},\n",
       " 'potted': {'pos': '0', 'neg': '0'},\n",
       " 'unabridged': {'pos': '0', 'neg': '0'},\n",
       " 'uncut': {'pos': '0.375', 'neg': '0.25'},\n",
       " 'absolute': {'pos': '0', 'neg': '0.25'},\n",
       " 'direct': {'pos': '0.125', 'neg': '0'},\n",
       " 'unquestioning': {'pos': '0.25', 'neg': '0.625'},\n",
       " 'infinite': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'living': {'pos': '0', 'neg': '0'},\n",
       " 'relative': {'pos': '0', 'neg': '0'},\n",
       " 'relational': {'pos': '0', 'neg': '0'},\n",
       " 'absorptive': {'pos': '0', 'neg': '0'},\n",
       " 'sorbefacient': {'pos': '0.375', 'neg': '0'},\n",
       " 'assimilatory': {'pos': '0', 'neg': '0.75'},\n",
       " 'hygroscopic': {'pos': '0', 'neg': '0'},\n",
       " 'receptive': {'pos': '0.25', 'neg': '0'},\n",
       " 'shock-absorbent': {'pos': '0', 'neg': '0'},\n",
       " 'spongy': {'pos': '0', 'neg': '0'},\n",
       " 'thirsty': {'pos': '0.25', 'neg': '0'},\n",
       " 'nonabsorptive': {'pos': '0', 'neg': '0.5'},\n",
       " 'resistant': {'pos': '0', 'neg': '0.125'},\n",
       " 'surface-assimilative': {'pos': '0', 'neg': '0'},\n",
       " 'chemosorptive': {'pos': '0', 'neg': '0.25'},\n",
       " 'nonadsorptive': {'pos': '0', 'neg': '0.25'},\n",
       " 'absorbable': {'pos': '0.5', 'neg': '0'},\n",
       " 'adsorbate': {'pos': '0.375', 'neg': '0'},\n",
       " 'abstemious': {'pos': '0', 'neg': '0'},\n",
       " 'abstinent': {'pos': '0', 'neg': '0.625'},\n",
       " 'spartan': {'pos': '0', 'neg': '0'},\n",
       " 'gluttonous': {'pos': '0', 'neg': '0'},\n",
       " 'crapulous': {'pos': '0', 'neg': '0.5'},\n",
       " 'wolfish': {'pos': '0', 'neg': '0'},\n",
       " 'greedy': {'pos': '0.375', 'neg': '0.25'},\n",
       " 'swinish': {'pos': '0.25', 'neg': '0.625'},\n",
       " 'too-greedy': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'abstract': {'pos': '0', 'neg': '0'},\n",
       " 'notional': {'pos': '0', 'neg': '0.75'},\n",
       " 'conceptual': {'pos': '0.375', 'neg': '0.25'},\n",
       " 'ideal': {'pos': '0', 'neg': '0'},\n",
       " 'ideological': {'pos': '0', 'neg': '0'},\n",
       " 'concrete': {'pos': '0', 'neg': '0'},\n",
       " 'objective': {'pos': '0', 'neg': '0'},\n",
       " 'tangible': {'pos': '0', 'neg': '0'},\n",
       " 'abundant': {'pos': '0', 'neg': '0.25'},\n",
       " 'galore': {'pos': '0.125', 'neg': '0'},\n",
       " 'rich': {'pos': '0', 'neg': '0'},\n",
       " 'voluminous': {'pos': '0', 'neg': '0'},\n",
       " 'easy': {'pos': '0.25', 'neg': '0'},\n",
       " 'riotous': {'pos': '0.375', 'neg': '0.625'},\n",
       " 'thick': {'pos': '0', 'neg': '0'},\n",
       " 'long': {'pos': '0', 'neg': '0'},\n",
       " 'rife': {'pos': '0', 'neg': '0'},\n",
       " 'plentiful': {'pos': '0.25', 'neg': '0'},\n",
       " 'rampant': {'pos': '0', 'neg': '0.625'},\n",
       " 'rank': {'pos': '0.625', 'neg': '0.125'},\n",
       " 'superabundant': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'teeming': {'pos': '0', 'neg': '0'},\n",
       " 'torrential': {'pos': '0', 'neg': '0'},\n",
       " 'verdant': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'scarce': {'pos': '0', 'neg': '0.25'},\n",
       " 'rare': {'pos': '0', 'neg': '0'},\n",
       " 'tight': {'pos': '0.375', 'neg': '0'},\n",
       " 'mistreated': {'pos': '0', 'neg': '0.625'},\n",
       " 'battered': {'pos': '0', 'neg': '0.75'},\n",
       " 'unabused': {'pos': '0.375', 'neg': '0.25'},\n",
       " 'acceptable': {'pos': '0.625', 'neg': '0'},\n",
       " 'bankable': {'pos': '0', 'neg': '0'},\n",
       " 'unimpeachable': {'pos': '0', 'neg': '0.75'},\n",
       " 'unobjectionable': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'unacceptable': {'pos': '0', 'neg': '0.75'},\n",
       " 'objectionable': {'pos': '0', 'neg': '0.375'},\n",
       " 'accessible': {'pos': '0.125', 'neg': '0'},\n",
       " 'reachable': {'pos': '0.375', 'neg': '0'},\n",
       " 'getatable': {'pos': '0.625', 'neg': '0'},\n",
       " 'ready_to_hand': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'unaccessible': {'pos': '0.5', 'neg': '0.125'},\n",
       " 'remote': {'pos': '0', 'neg': '0'},\n",
       " 'untrodden': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'unreached': {'pos': '0', 'neg': '0'},\n",
       " 'ungetatable': {'pos': '0', 'neg': '0.625'},\n",
       " 'accommodative': {'pos': '0.5', 'neg': '0'},\n",
       " 'obliging': {'pos': '0.75', 'neg': '0'},\n",
       " 'unobliging': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'uncooperative': {'pos': '0', 'neg': '0.625'},\n",
       " 'accurate': {'pos': '0.5', 'neg': '0'},\n",
       " 'faithful': {'pos': '0.375', 'neg': '0'},\n",
       " 'dead-on': {'pos': '0.625', 'neg': '0.25'},\n",
       " 'high-fidelity': {'pos': '0.5', 'neg': '0.125'},\n",
       " 'surgical': {'pos': '0', 'neg': '0'},\n",
       " 'straight': {'pos': '0', 'neg': '0'},\n",
       " 'true': {'pos': '0', 'neg': '0'},\n",
       " 'veracious': {'pos': '0.375', 'neg': '0'},\n",
       " 'inaccurate': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'outside': {'pos': '0', 'neg': '0'},\n",
       " 'wrong': {'pos': '0', 'neg': '0.75'},\n",
       " 'unfaithful': {'pos': '0.5', 'neg': '0.125'},\n",
       " 'wide_of_the_mark': {'pos': '0', 'neg': '0.625'},\n",
       " 'accustomed': {'pos': '0.125', 'neg': '0'},\n",
       " 'wont_to': {'pos': '0', 'neg': '0.375'},\n",
       " 'unaccustomed': {'pos': '0.25', 'neg': '0.625'},\n",
       " 'new': {'pos': '0.25', 'neg': '0'},\n",
       " 'unused': {'pos': '0.5', 'neg': '0'},\n",
       " 'acidic': {'pos': '0', 'neg': '0.125'},\n",
       " 'acid': {'pos': '0', 'neg': '0.25'},\n",
       " 'acid-forming': {'pos': '0', 'neg': '0.5'},\n",
       " 'alkaline': {'pos': '0', 'neg': '0'},\n",
       " 'alkalescent': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'basic': {'pos': '0', 'neg': '0'},\n",
       " 'base-forming': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'saltlike': {'pos': '0.25', 'neg': '0.125'},\n",
       " 'amphoteric': {'pos': '0.5', 'neg': '0'},\n",
       " 'acid-loving': {'pos': '0', 'neg': '0.25'},\n",
       " 'aciduric': {'pos': '0', 'neg': '0'},\n",
       " 'alkaline-loving': {'pos': '0', 'neg': '0.25'},\n",
       " 'acknowledged': {'pos': '0.25', 'neg': '0'},\n",
       " 'recognized': {'pos': '0.5', 'neg': '0'},\n",
       " 'self-confessed': {'pos': '0', 'neg': '0.125'},\n",
       " 'assumptive': {'pos': '0.25', 'neg': '0'},\n",
       " 'declarable': {'pos': '0.375', 'neg': '0'},\n",
       " 'granted': {'pos': '0', 'neg': '0'},\n",
       " 'putative': {'pos': '0.125', 'neg': '0'},\n",
       " 'unacknowledged': {'pos': '0', 'neg': '0.625'},\n",
       " 'unvalued': {'pos': '0', 'neg': '0.375'},\n",
       " 'unavowed': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'unconfessed': {'pos': '0', 'neg': '0.125'},\n",
       " 'unrecognized': {'pos': '0.125', 'neg': '0.75'},\n",
       " 'acquisitive': {'pos': '0', 'neg': '0'},\n",
       " 'accumulative': {'pos': '0.375', 'neg': '0'},\n",
       " 'prehensile': {'pos': '0.625', 'neg': '0'},\n",
       " 'possessive': {'pos': '0', 'neg': '0'},\n",
       " 'plundering': {'pos': '0', 'neg': '0'},\n",
       " 'predatory': {'pos': '0', 'neg': '0'},\n",
       " 'voracious': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'sordid': {'pos': '0', 'neg': '0.75'},\n",
       " 'unacquisitive': {'pos': '0', 'neg': '0.5'},\n",
       " 'acropetal': {'pos': '0', 'neg': '0'},\n",
       " 'basipetal': {'pos': '0', 'neg': '0'},\n",
       " 'active': {'pos': '0', 'neg': '0'},\n",
       " 'astir': {'pos': '0', 'neg': '0'},\n",
       " 'gymnastic': {'pos': '0', 'neg': '0'},\n",
       " 'spry': {'pos': '0', 'neg': '0'},\n",
       " 'hot': {'pos': '0', 'neg': '0'},\n",
       " 'overactive': {'pos': '0.25', 'neg': '0'},\n",
       " 'on_the_go': {'pos': '0.125', 'neg': '0'},\n",
       " 'sporty': {'pos': '0.375', 'neg': '0'},\n",
       " 'inactive': {'pos': '0', 'neg': '0.625'},\n",
       " 'deskbound': {'pos': '0.125', 'neg': '0'},\n",
       " 'dormant': {'pos': '0.25', 'neg': '0.375'},\n",
       " 'underactive': {'pos': '0', 'neg': '0.625'},\n",
       " 'torpid': {'pos': '0', 'neg': '0'},\n",
       " 'sedentary': {'pos': '0.125', 'neg': '0'},\n",
       " 'activated': {'pos': '0', 'neg': '0.125'},\n",
       " 'off': {'pos': '0', 'neg': '0'},\n",
       " 'retired': {'pos': '0', 'neg': '0.625'},\n",
       " 'brisk': {'pos': '0.25', 'neg': '0.125'},\n",
       " 'bustling': {'pos': '0.5', 'neg': '0'},\n",
       " 'busy': {'pos': '0.375', 'neg': '0'},\n",
       " 'going': {'pos': '0', 'neg': '0.5'},\n",
       " 'open': {'pos': '0', 'neg': '0'},\n",
       " 'springy': {'pos': '0', 'neg': '0'},\n",
       " 'dark': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'dead': {'pos': '0', 'neg': '0.5'},\n",
       " 'sluggish': {'pos': '0', 'neg': '0.5'},\n",
       " 'strikebound': {'pos': '0', 'neg': '0'},\n",
       " 'progressive': {'pos': '0', 'neg': '0'},\n",
       " 'dead-end': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'flat': {'pos': '0', 'neg': '0'},\n",
       " 'indolent': {'pos': '0', 'neg': '0'},\n",
       " 'latent': {'pos': '0', 'neg': '0.625'},\n",
       " 'quiescent': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'activistic': {'pos': '0', 'neg': '0'},\n",
       " 'hands-on': {'pos': '0', 'neg': '0'},\n",
       " 'proactive': {'pos': '0', 'neg': '0'},\n",
       " 'passive': {'pos': '0', 'neg': '0'},\n",
       " 'hands-off': {'pos': '0', 'neg': '0.625'},\n",
       " 'unresisting': {'pos': '0', 'neg': '0.75'},\n",
       " 'eruptive': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'extinct': {'pos': '0', 'neg': '0'},\n",
       " 'live': {'pos': '0.25', 'neg': '0'},\n",
       " 'dynamic': {'pos': '0', 'neg': '0'},\n",
       " 'stative': {'pos': '0', 'neg': '0'},\n",
       " 'counteractive': {'pos': '0', 'neg': '0.5'},\n",
       " 'surface-active': {'pos': '0', 'neg': '0'},\n",
       " 'quiet': {'pos': '0', 'neg': '0'},\n",
       " 'existent': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'effective': {'pos': '0.25', 'neg': '0'},\n",
       " 'potential': {'pos': '0', 'neg': '0.25'},\n",
       " 'acute': {'pos': '0', 'neg': '0'},\n",
       " 'subacute': {'pos': '0', 'neg': '0'},\n",
       " 'chronic': {'pos': '0', 'neg': '0.375'},\n",
       " 'degenerative': {'pos': '0', 'neg': '0.375'},\n",
       " 'virulent': {'pos': '0', 'neg': '0.75'},\n",
       " 'highly_infective': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'deadly': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'avirulent': {'pos': '0', 'neg': '0.875'},\n",
       " 'adaptive': {'pos': '0.25', 'neg': '0'},\n",
       " 'reconciling': {'pos': '0.625', 'neg': '0.125'},\n",
       " 'adaptational': {'pos': '0', 'neg': '0'},\n",
       " 'adjustive': {'pos': '0.625', 'neg': '0.125'},\n",
       " 'maladaptive': {'pos': '0.5', 'neg': '0.375'},\n",
       " 'nonadaptive': {'pos': '0', 'neg': '0'},\n",
       " 'maladjustive': {'pos': '0.375', 'neg': '0.25'},\n",
       " 'addicted': {'pos': '0', 'neg': '0'},\n",
       " 'alcoholic': {'pos': '0', 'neg': '0'},\n",
       " 'strung-out': {'pos': '0', 'neg': '0'},\n",
       " 'unaddicted': {'pos': '0', 'neg': '0.125'},\n",
       " 'clean': {'pos': '0.25', 'neg': '0'},\n",
       " 'habit-forming': {'pos': '0', 'neg': '0.625'},\n",
       " 'nonaddictive': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'additive': {'pos': '0', 'neg': '0'},\n",
       " 'cumulative': {'pos': '0', 'neg': '0'},\n",
       " 'addible': {'pos': '0.5', 'neg': '0'},\n",
       " 'extra': {'pos': '0.375', 'neg': '0'},\n",
       " 'completing': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'incremental': {'pos': '0', 'neg': '0'},\n",
       " 'intercalary': {'pos': '0', 'neg': '0'},\n",
       " 'summative': {'pos': '0', 'neg': '0'},\n",
       " 'supplementary': {'pos': '0', 'neg': '0'},\n",
       " 'subtractive': {'pos': '0.25', 'neg': '0'},\n",
       " 'ablative': {'pos': '0', 'neg': '0'},\n",
       " 'reductive': {'pos': '0', 'neg': '0.625'},\n",
       " 'addressed': {'pos': '0.125', 'neg': '0'},\n",
       " 'self-addressed': {'pos': '0', 'neg': '0'},\n",
       " 'unaddressed': {'pos': '0', 'neg': '0.125'},\n",
       " 'equal': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'up_to': {'pos': '0.5', 'neg': '0'},\n",
       " 'competent': {'pos': '0.75', 'neg': '0'},\n",
       " 'unequal': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'wanting': {'pos': '0', 'neg': '0.625'},\n",
       " 'unequal_to': {'pos': '0', 'neg': '0.25'},\n",
       " 'understaffed': {'pos': '0', 'neg': '0.75'},\n",
       " 'adhesive': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'adherent': {'pos': '0', 'neg': '0'},\n",
       " 'agglutinative': {'pos': '0', 'neg': '0'},\n",
       " 'bondable': {'pos': '0.5', 'neg': '0'},\n",
       " 'tenacious': {'pos': '0.375', 'neg': '0.5'},\n",
       " 'cohesive': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'viscous': {'pos': '0.25', 'neg': '0'},\n",
       " 'icky': {'pos': '0', 'neg': '0'},\n",
       " 'gum-like': {'pos': '0', 'neg': '0'},\n",
       " 'gummy': {'pos': '0', 'neg': '0.25'},\n",
       " 'tarry': {'pos': '0.125', 'neg': '0'},\n",
       " 'self-sealing': {'pos': '0.625', 'neg': '0'},\n",
       " 'stick-on': {'pos': '0', 'neg': '0.5'},\n",
       " 'sticky': {'pos': '0', 'neg': '0'},\n",
       " 'nonadhesive': {'pos': '0', 'neg': '0.75'},\n",
       " 'nonviscid': {'pos': '0', 'neg': '0.625'},\n",
       " 'nonresiny': {'pos': '0', 'neg': '0.5'},\n",
       " 'ungummed': {'pos': '0', 'neg': '0.75'},\n",
       " 'procedural': {'pos': '0', 'neg': '0'},\n",
       " 'substantive': {'pos': '0', 'neg': '0'},\n",
       " 'adoptable': {'pos': '0.75', 'neg': '0'},\n",
       " 'unadoptable': {'pos': '0', 'neg': '0'},\n",
       " 'decorated': {'pos': '0.375', 'neg': '0'},\n",
       " 'spangly': {'pos': '0', 'neg': '0.375'},\n",
       " 'bedaubed': {'pos': '0', 'neg': '0.5'},\n",
       " 'spectacled': {'pos': '0', 'neg': '0.25'},\n",
       " 'raised': {'pos': '0', 'neg': '0.125'},\n",
       " 'buttony': {'pos': '0', 'neg': '0'},\n",
       " 'carbuncled': {'pos': '0', 'neg': '0'},\n",
       " 'cloisonne': {'pos': '0', 'neg': '0'},\n",
       " 'tinselly': {'pos': '0', 'neg': '0'},\n",
       " 'plumed': {'pos': '0', 'neg': '0.25'},\n",
       " 'tufted': {'pos': '0', 'neg': '0.125'},\n",
       " 'crested': {'pos': '0', 'neg': '0'},\n",
       " 'crocketed': {'pos': '0', 'neg': '0'},\n",
       " 'plumy': {'pos': '0', 'neg': '0.375'},\n",
       " 'ruffled': {'pos': '0', 'neg': '0'},\n",
       " 'fringed': {'pos': '0', 'neg': '0'},\n",
       " 'gilt-edged': {'pos': '0.75', 'neg': '0'},\n",
       " 'inflamed': {'pos': '0', 'neg': '0.875'},\n",
       " 'inlaid': {'pos': '0', 'neg': '0.125'},\n",
       " 'inwrought': {'pos': '0', 'neg': '0'},\n",
       " 'tessellated': {'pos': '0', 'neg': '0.125'},\n",
       " 'mounted': {'pos': '0', 'neg': '0'},\n",
       " 'wainscoted': {'pos': '0', 'neg': '0.125'},\n",
       " 'studded': {'pos': '0', 'neg': '0.375'},\n",
       " 'tapestried': {'pos': '0', 'neg': '0.125'},\n",
       " 'tasselled': {'pos': '0', 'neg': '0.125'},\n",
       " 'tricked-out': {'pos': '0', 'neg': '0.125'},\n",
       " 'undecorated': {'pos': '0.25', 'neg': '0.625'},\n",
       " 'unornamented': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'untufted': {'pos': '0.375', 'neg': '0.375'},\n",
       " 'cholinergic': {'pos': '0', 'neg': '0'},\n",
       " 'anticholinergic': {'pos': '0', 'neg': '0'},\n",
       " 'adroit': {'pos': '0.25', 'neg': '0'},\n",
       " 'neat': {'pos': '0.5', 'neg': '0'},\n",
       " 'ingenious': {'pos': '0.625', 'neg': '0'},\n",
       " 'coordinated': {'pos': '0', 'neg': '0'},\n",
       " 'dextrous': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'handy': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'nimble-fingered': {'pos': '0', 'neg': '0'},\n",
       " 'quick-witted': {'pos': '0.5', 'neg': '0'},\n",
       " 'maladroit': {'pos': '0.25', 'neg': '0.375'},\n",
       " 'left-handed': {'pos': '0', 'neg': '0'},\n",
       " 'tactless': {'pos': '0.5', 'neg': '0.125'},\n",
       " 'uncoordinated': {'pos': '0.5', 'neg': '0.25'},\n",
       " 'unmechanical': {'pos': '0', 'neg': '0.25'},\n",
       " 'advantageous': {'pos': '0.375', 'neg': '0'},\n",
       " 'good': {'pos': '0.5', 'neg': '0'},\n",
       " 'positive': {'pos': '0', 'neg': '0'},\n",
       " 'preferential': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'disadvantageous': {'pos': '0.75', 'neg': '0.25'},\n",
       " 'negative': {'pos': '0', 'neg': '0.25'},\n",
       " 'adventurous': {'pos': '0.625', 'neg': '0.25'},\n",
       " 'venturous': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'sporting': {'pos': '0', 'neg': '0'},\n",
       " 'swashbuckling': {'pos': '0.375', 'neg': '0.25'},\n",
       " 'unadventurous': {'pos': '0.25', 'neg': '0.375'},\n",
       " 'safe': {'pos': '0', 'neg': '0.25'},\n",
       " 'advisable': {'pos': '0.625', 'neg': '0'},\n",
       " 'better': {'pos': '0', 'neg': '0'},\n",
       " 'well': {'pos': '0', 'neg': '0'},\n",
       " 'unadvisable': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'well-advised': {'pos': '0.5', 'neg': '0'},\n",
       " 'considered': {'pos': '0', 'neg': '0'},\n",
       " 'unadvised': {'pos': '0.125', 'neg': '0'},\n",
       " 'aerophilous': {'pos': '0', 'neg': '0'},\n",
       " 'aerobiotic': {'pos': '0', 'neg': '0'},\n",
       " 'oxidative': {'pos': '0', 'neg': '0'},\n",
       " 'anaerobiotic': {'pos': '0', 'neg': '0.375'},\n",
       " 'aerobic': {'pos': '0.5', 'neg': '0'},\n",
       " 'anaerobic': {'pos': '0', 'neg': '0.25'},\n",
       " 'esthetical': {'pos': '0.625', 'neg': '0'},\n",
       " 'artistic': {'pos': '0', 'neg': '0'},\n",
       " 'enhancive': {'pos': '0', 'neg': '0'},\n",
       " 'painterly': {'pos': '0.25', 'neg': '0'},\n",
       " 'sensuous': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'unaesthetic': {'pos': '0.5', 'neg': '0.5'},\n",
       " 'unartistic': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'affected': {'pos': '0.375', 'neg': '0'},\n",
       " 'impressed': {'pos': '0.5', 'neg': '0.5'},\n",
       " 'struck': {'pos': '0', 'neg': '0.375'},\n",
       " 'stage-struck': {'pos': '0.125', 'neg': '0'},\n",
       " 'subject': {'pos': '0', 'neg': '0'},\n",
       " 'taken': {'pos': '0.25', 'neg': '0'},\n",
       " 'wonder-struck': {'pos': '0', 'neg': '0.5'},\n",
       " 'unaffected': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'immune': {'pos': '0', 'neg': '0'},\n",
       " 'superior': {'pos': '0', 'neg': '0'},\n",
       " 'unimpressed': {'pos': '0', 'neg': '0.625'},\n",
       " 'untouched': {'pos': '0', 'neg': '0.625'},\n",
       " 'unnatural': {'pos': '0', 'neg': '0.75'},\n",
       " 'strained': {'pos': '0.25', 'neg': '0'},\n",
       " 'stilted': {'pos': '0', 'neg': '0.25'},\n",
       " 'elocutionary': {'pos': '0', 'neg': '0'},\n",
       " 'mannered': {'pos': '0', 'neg': '0.375'},\n",
       " 'plummy': {'pos': '0.75', 'neg': '0'},\n",
       " 'natural': {'pos': '0', 'neg': '0'},\n",
       " 'unmannered': {'pos': '0', 'neg': '0.375'},\n",
       " 'unselfconscious': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'unstilted': {'pos': '0', 'neg': '0'},\n",
       " 'affirmatory': {'pos': '0.5', 'neg': '0'},\n",
       " 'assentient': {'pos': '0.25', 'neg': '0'},\n",
       " 'dissident': {'pos': '0', 'neg': '0.625'},\n",
       " 'acceptive': {'pos': '0.25', 'neg': '0'},\n",
       " 'accepting': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'rejective': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'dismissive': {'pos': '0.5', 'neg': '0.25'},\n",
       " 'repudiative': {'pos': '0', 'neg': '0'},\n",
       " 'afloat': {'pos': '0', 'neg': '0'},\n",
       " 'adrift': {'pos': '0', 'neg': '0'},\n",
       " 'floating': {'pos': '0', 'neg': '0'},\n",
       " 'waterborne': {'pos': '0', 'neg': '0'},\n",
       " 'aground': {'pos': '0', 'neg': '0'},\n",
       " 'afraid': {'pos': '0', 'neg': '0.75'},\n",
       " 'acrophobic': {'pos': '0', 'neg': '0.75'},\n",
       " 'afeared': {'pos': '0', 'neg': '0.125'},\n",
       " 'shocked': {'pos': '0.25', 'neg': '0'},\n",
       " 'agoraphobic': {'pos': '0', 'neg': '0.75'},\n",
       " 'alarmed': {'pos': '0', 'neg': '0.625'},\n",
       " 'algophobic': {'pos': '0', 'neg': '0.875'},\n",
       " 'apprehensive': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'hangdog': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'claustrophobic': {'pos': '0', 'neg': '0.125'},\n",
       " 'fearful': {'pos': '0', 'neg': '0.5'},\n",
       " 'scared': {'pos': '0', 'neg': '0.125'},\n",
       " 'horror-struck': {'pos': '0', 'neg': '0.25'},\n",
       " 'hunted': {'pos': '0.625', 'neg': '0.125'},\n",
       " 'hydrophobic': {'pos': '0', 'neg': '0.625'},\n",
       " 'mysophobic': {'pos': '0', 'neg': '0.75'},\n",
       " 'terrified': {'pos': '0', 'neg': '0'},\n",
       " 'numb': {'pos': '0', 'neg': '0.25'},\n",
       " 'shitless': {'pos': '0', 'neg': '0.375'},\n",
       " 'terror-struck': {'pos': '0', 'neg': '0.5'},\n",
       " 'triskaidekaphobic': {'pos': '0', 'neg': '0.625'},\n",
       " 'unnerved': {'pos': '0', 'neg': '0.625'},\n",
       " 'white-lipped': {'pos': '0.125', 'neg': '0'},\n",
       " 'xenophobic': {'pos': '0', 'neg': '0.75'},\n",
       " 'unafraid': {'pos': '0.25', 'neg': '0.125'},\n",
       " 'unapprehensive': {'pos': '0', 'neg': '0.625'},\n",
       " 'unshrinking': {'pos': '0.25', 'neg': '0.375'},\n",
       " 'unfrightened': {'pos': '0.625', 'neg': '0.25'},\n",
       " 'aggressive': {'pos': '0.5', 'neg': '0'},\n",
       " 'combative': {'pos': '0', 'neg': '0.25'},\n",
       " 'militant': {'pos': '0', 'neg': '0'},\n",
       " 'high-pressure': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'hostile': {'pos': '0.125', 'neg': '0'},\n",
       " 'in-your-face': {'pos': '0.25', 'neg': '0'},\n",
       " 'obstreperous': {'pos': '0', 'neg': '0.5'},\n",
       " 'vulturous': {'pos': '0', 'neg': '0'},\n",
       " 'rough': {'pos': '0', 'neg': '0'},\n",
       " 'scrappy': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'truculent': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'unaggressive': {'pos': '0', 'neg': '0.625'},\n",
       " 'low-pressure': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'agitated': {'pos': '0', 'neg': '0.125'},\n",
       " 'worked_up': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'overwrought': {'pos': '0', 'neg': '0.125'},\n",
       " 'shaken': {'pos': '0', 'neg': '0.5'},\n",
       " 'hectic': {'pos': '0.375', 'neg': '0.375'},\n",
       " 'phrenetic': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'hysterical': {'pos': '0.375', 'neg': '0.375'},\n",
       " 'psychedelic': {'pos': '0', 'neg': '0.125'},\n",
       " 'wild-eyed': {'pos': '0', 'neg': '0.375'},\n",
       " 'unagitated': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'turbulent': {'pos': '0', 'neg': '0.75'},\n",
       " 'churning': {'pos': '0.25', 'neg': '0'},\n",
       " 'jolted': {'pos': '0', 'neg': '0'},\n",
       " 'seething': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'stirred': {'pos': '0', 'neg': '0'},\n",
       " 'nonturbulent': {'pos': '0', 'neg': '0.25'},\n",
       " 'unstirred': {'pos': '0.5', 'neg': '0.25'},\n",
       " 'agreeable': {'pos': '0.125', 'neg': '0'},\n",
       " 'disagreeable': {'pos': '0.125', 'neg': '0.875'},\n",
       " 'vexing': {'pos': '0.125', 'neg': '0.875'},\n",
       " 'harsh': {'pos': '0', 'neg': '0'},\n",
       " 'trying': {'pos': '0', 'neg': '0.5'},\n",
       " 'unsweet': {'pos': '0', 'neg': '0'},\n",
       " 'air-to-surface': {'pos': '0', 'neg': '0'},\n",
       " 'air-to-air': {'pos': '0', 'neg': '0'},\n",
       " 'surface-to-air': {'pos': '0', 'neg': '0'},\n",
       " 'watchful': {'pos': '0', 'neg': '0.625'},\n",
       " 'wakeful': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'fly': {'pos': '0', 'neg': '0'},\n",
       " 'wide-awake': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'sleepless': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'unwatchful': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'algorithmic': {'pos': '0', 'neg': '0'},\n",
       " 'recursive': {'pos': '0', 'neg': '0'},\n",
       " 'heuristic': {'pos': '0', 'neg': '0'},\n",
       " 'trial-and-error': {'pos': '0.125', 'neg': '0'},\n",
       " 'alienable': {'pos': '0', 'neg': '0'},\n",
       " 'appropriable': {'pos': '0', 'neg': '0'},\n",
       " 'transferrable': {'pos': '0.125', 'neg': '0'},\n",
       " 'unalienable': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'inviolable': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'non-negotiable': {'pos': '0.5', 'neg': '0'},\n",
       " 'untransferable': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'liveborn': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'viable': {'pos': '0.5', 'neg': '0'},\n",
       " 'vital': {'pos': '0.5', 'neg': '0'},\n",
       " 'gone': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'assassinated': {'pos': '0', 'neg': '0'},\n",
       " 'exsanguinous': {'pos': '0', 'neg': '0.5'},\n",
       " 'brain_dead': {'pos': '0', 'neg': '0'},\n",
       " 'pulseless': {'pos': '0', 'neg': '0.75'},\n",
       " 'cold': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'd.o.a.': {'pos': '0', 'neg': '0'},\n",
       " 'deathly': {'pos': '0', 'neg': '0'},\n",
       " 'defunct': {'pos': '0', 'neg': '0.75'},\n",
       " 'doomed': {'pos': '0', 'neg': '0.375'},\n",
       " 'executed': {'pos': '0', 'neg': '0'},\n",
       " 'fallen': {'pos': '0', 'neg': '0'},\n",
       " 'late': {'pos': '0', 'neg': '0'},\n",
       " 'lifeless': {'pos': '0', 'neg': '0'},\n",
       " 'murdered': {'pos': '0', 'neg': '0'},\n",
       " 'nonviable': {'pos': '0', 'neg': '0.625'},\n",
       " 'slain': {'pos': '0', 'neg': '0'},\n",
       " 'stillborn': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'stone-dead': {'pos': '0', 'neg': '0.375'},\n",
       " 'apocrine': {'pos': '0', 'neg': '0'},\n",
       " 'eccrine': {'pos': '0.25', 'neg': '0'},\n",
       " 'artesian': {'pos': '0', 'neg': '0'},\n",
       " 'subartesian': {'pos': '0', 'neg': '0.125'},\n",
       " 'in_play': {'pos': '0', 'neg': '0'},\n",
       " 'out': {'pos': '0', 'neg': '0'},\n",
       " 'out_of_play': {'pos': '0', 'neg': '0'},\n",
       " 'alphabetical': {'pos': '0', 'neg': '0'},\n",
       " 'abecedarian': {'pos': '0', 'neg': '0'},\n",
       " 'alphabetized': {'pos': '0', 'neg': '0'},\n",
       " 'analphabetic': {'pos': '0', 'neg': '0.125'},\n",
       " 'altricial': {'pos': '0', 'neg': '0'},\n",
       " 'precocial': {'pos': '0.25', 'neg': '0'},\n",
       " 'selfless': {'pos': '0.875', 'neg': '0'},\n",
       " 'self-centred': {'pos': '0.375', 'neg': '0'},\n",
       " 'self-involved': {'pos': '0.5', 'neg': '0'},\n",
       " 'ambiguous': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'double-barrelled': {'pos': '0', 'neg': '0'},\n",
       " 'double-edged': {'pos': '0', 'neg': '0'},\n",
       " 'oracular': {'pos': '0', 'neg': '0'},\n",
       " 'multivalent': {'pos': '0', 'neg': '0'},\n",
       " 'polysemous': {'pos': '0', 'neg': '0'},\n",
       " 'uncertain': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'unambiguous': {'pos': '0.375', 'neg': '0'},\n",
       " 'monosemous': {'pos': '0.125', 'neg': '0'},\n",
       " 'ambitious': {'pos': '0.5', 'neg': '0.125'},\n",
       " 'pushy': {'pos': '0.625', 'neg': '0'},\n",
       " 'wishful': {'pos': '0.375', 'neg': '0'},\n",
       " 'driven': {'pos': '0.375', 'neg': '0'},\n",
       " 'would-be': {'pos': '0.25', 'neg': '0'},\n",
       " 'overambitious': {'pos': '0.375', 'neg': '0.25'},\n",
       " 'unambitious': {'pos': '0.5', 'neg': '0'},\n",
       " 'shiftless': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'ametropic': {'pos': '0', 'neg': '0.25'},\n",
       " 'emmetropic': {'pos': '0', 'neg': '0'},\n",
       " 'ample': {'pos': '0', 'neg': '0'},\n",
       " 'generous': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'wide-cut': {'pos': '0', 'neg': '0'},\n",
       " 'stingy': {'pos': '0', 'neg': '0.625'},\n",
       " 'spare': {'pos': '0', 'neg': '0'},\n",
       " 'exiguous': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'hand-to-mouth': {'pos': '0', 'neg': '0.5'},\n",
       " 'hardscrabble': {'pos': '0', 'neg': '0.375'},\n",
       " 'paltry': {'pos': '0', 'neg': '0'},\n",
       " 'anabolic': {'pos': '0', 'neg': '0'},\n",
       " 'energy-storing': {'pos': '0', 'neg': '0'},\n",
       " 'katabolic': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'energy-releasing': {'pos': '0', 'neg': '0'},\n",
       " 'anaclinal': {'pos': '0', 'neg': '0'},\n",
       " 'cataclinal': {'pos': '0', 'neg': '0'},\n",
       " 'stigmatic': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'astigmatic': {'pos': '0', 'neg': '0'},\n",
       " 'anticlinal': {'pos': '0', 'neg': '0'},\n",
       " 'synclinal': {'pos': '0', 'neg': '0'},\n",
       " 'anadromous': {'pos': '0', 'neg': '0'},\n",
       " 'catadromous': {'pos': '0', 'neg': '0'},\n",
       " 'diadromous': {'pos': '0', 'neg': '0'},\n",
       " 'anabatic': {'pos': '0', 'neg': '0'},\n",
       " 'katabatic': {'pos': '0', 'neg': '0'},\n",
       " 'anal_retentive': {'pos': '0', 'neg': '0'},\n",
       " 'oral': {'pos': '0', 'neg': '0'},\n",
       " 'linear': {'pos': '0.25', 'neg': '0'},\n",
       " 'digital': {'pos': '0.125', 'neg': '0'},\n",
       " 'analytical': {'pos': '0', 'neg': '0'},\n",
       " 'synthetical': {'pos': '0', 'neg': '0'},\n",
       " 'uninflected': {'pos': '0', 'neg': '0.125'},\n",
       " 'isolating': {'pos': '0', 'neg': '0'},\n",
       " 'synthetic': {'pos': '0', 'neg': '0.5'},\n",
       " 'polysynthetic': {'pos': '0', 'neg': '0'},\n",
       " 'inflectional': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'derivational': {'pos': '0', 'neg': '0.25'},\n",
       " 'apocarpous': {'pos': '0', 'neg': '0'},\n",
       " 'syncarpous': {'pos': '0', 'neg': '0'},\n",
       " 'angry': {'pos': '0', 'neg': '0.875'},\n",
       " 'provoked': {'pos': '0', 'neg': '0.5'},\n",
       " 'maddened': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'black': {'pos': '0', 'neg': '0'},\n",
       " 'irascible': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'hot_under_the_collar': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'sore': {'pos': '0', 'neg': '0'},\n",
       " 'umbrageous': {'pos': '0', 'neg': '0.375'},\n",
       " 'ireful': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'livid': {'pos': '0', 'neg': '0.375'},\n",
       " 'smouldering': {'pos': '0.5', 'neg': '0.25'},\n",
       " 'wrothful': {'pos': '0', 'neg': '0.25'},\n",
       " 'unangry': {'pos': '0', 'neg': '0.125'},\n",
       " 'resentful': {'pos': '0', 'neg': '0.875'},\n",
       " 'bitter': {'pos': '0', 'neg': '0'},\n",
       " 'rancorous': {'pos': '0.375', 'neg': '0.25'},\n",
       " 'unresentful': {'pos': '0', 'neg': '0.5'},\n",
       " 'unbitter': {'pos': '0', 'neg': '0.75'},\n",
       " 'sentient': {'pos': '0.125', 'neg': '0'},\n",
       " 'sensate': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'insentient': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'unfeeling': {'pos': '0.25', 'neg': '0.625'},\n",
       " 'animate': {'pos': '0', 'neg': '0'},\n",
       " 'nonliving': {'pos': '0', 'neg': '0.75'},\n",
       " 'nonconscious': {'pos': '0', 'neg': '0.5'},\n",
       " 'animated': {'pos': '0', 'neg': '0'},\n",
       " 'spirited': {'pos': '0.5', 'neg': '0'},\n",
       " 'revived': {'pos': '0.25', 'neg': '0'},\n",
       " 'unanimated': {'pos': '0.375', 'neg': '0.5'},\n",
       " 'wan': {'pos': '0', 'neg': '0.375'},\n",
       " 'enlivened': {'pos': '0.5', 'neg': '0'},\n",
       " 'perked_up': {'pos': '0.875', 'neg': '0'},\n",
       " 'unenlivened': {'pos': '0', 'neg': '0.625'},\n",
       " 'inanimate': {'pos': '0', 'neg': '0'},\n",
       " 'anonymous': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'unnamed': {'pos': '0', 'neg': '0'},\n",
       " 'onymous': {'pos': '0', 'neg': '0'},\n",
       " 'binominal': {'pos': '0', 'neg': '0'},\n",
       " 'pseudonymous': {'pos': '0', 'neg': '0'},\n",
       " 'antemortem': {'pos': '0', 'neg': '0'},\n",
       " 'postmortem': {'pos': '0', 'neg': '0'},\n",
       " 'antecedent': {'pos': '0', 'neg': '0'},\n",
       " 'prior': {'pos': '0', 'neg': '0'},\n",
       " 'prevenient': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'preexisting': {'pos': '0', 'neg': '0.375'},\n",
       " 'subsequent': {'pos': '0', 'neg': '0'},\n",
       " 'sequent': {'pos': '0', 'neg': '0'},\n",
       " 'ulterior': {'pos': '0.25', 'neg': '0.375'},\n",
       " 'antrorse': {'pos': '0', 'neg': '0'},\n",
       " 'retrorse': {'pos': '0', 'neg': '0'},\n",
       " 'decurved': {'pos': '0', 'neg': '0.125'},\n",
       " 'aquatic': {'pos': '0', 'neg': '0'},\n",
       " 'marine': {'pos': '0', 'neg': '0.125'},\n",
       " 'subaquatic': {'pos': '0', 'neg': '0'},\n",
       " 'underwater': {'pos': '0', 'neg': '0'},\n",
       " 'terrestrial': {'pos': '0', 'neg': '0'},\n",
       " 'onshore': {'pos': '0', 'neg': '0'},\n",
       " 'overland': {'pos': '0', 'neg': '0'},\n",
       " 'amphibious': {'pos': '0', 'neg': '0'},\n",
       " 'semiaquatic': {'pos': '0', 'neg': '0'},\n",
       " 'preceding': {'pos': '0', 'neg': '0.125'},\n",
       " 'above': {'pos': '0', 'neg': '0'},\n",
       " 'above-named': {'pos': '0', 'neg': '0.125'},\n",
       " 'foregoing': {'pos': '0', 'neg': '0'},\n",
       " 'prefatory': {'pos': '0', 'neg': '0'},\n",
       " 'precedent': {'pos': '0', 'neg': '0'},\n",
       " 'premedical': {'pos': '0', 'neg': '0'},\n",
       " 'propaedeutic': {'pos': '0', 'neg': '0'},\n",
       " 'previous': {'pos': '0', 'neg': '0.25'},\n",
       " 'succeeding': {'pos': '0', 'neg': '0.125'},\n",
       " 'consecutive': {'pos': '0', 'neg': '0.375'},\n",
       " 'ensuing': {'pos': '0', 'neg': '0'},\n",
       " 'undermentioned': {'pos': '0', 'neg': '0'},\n",
       " 'next': {'pos': '0', 'neg': '0'},\n",
       " 'in_line': {'pos': '0', 'neg': '0'},\n",
       " 'precedented': {'pos': '0.375', 'neg': '0'},\n",
       " 'unprecedented': {'pos': '0', 'neg': '0'},\n",
       " 'unexampled': {'pos': '0', 'neg': '0.625'},\n",
       " 'nonprehensile': {'pos': '0', 'neg': '0.125'},\n",
       " 'prenatal': {'pos': '0', 'neg': '0.125'},\n",
       " 'perinatal': {'pos': '0', 'neg': '0'},\n",
       " 'postpartum': {'pos': '0', 'neg': '0.125'},\n",
       " 'preprandial': {'pos': '0', 'neg': '0'},\n",
       " 'postprandial': {'pos': '0', 'neg': '0'},\n",
       " 'prewar': {'pos': '0', 'neg': '0'},\n",
       " 'postwar': {'pos': '0', 'neg': '0'},\n",
       " 'retrograde': {'pos': '0', 'neg': '0'},\n",
       " 'anterograde': {'pos': '0', 'neg': '0.125'},\n",
       " 'antemeridian': {'pos': '0', 'neg': '0'},\n",
       " 'ante_meridiem': {'pos': '0', 'neg': '0'},\n",
       " 'postmeridian': {'pos': '0', 'neg': '0'},\n",
       " 'post_meridiem': {'pos': '0', 'neg': '0'},\n",
       " 'anterior': {'pos': '0', 'neg': '0'},\n",
       " 'frontal': {'pos': '0', 'neg': '0'},\n",
       " 'prefrontal': {'pos': '0', 'neg': '0'},\n",
       " 'posterior': {'pos': '0', 'neg': '0'},\n",
       " 'hinder': {'pos': '0', 'neg': '0.375'},\n",
       " 'caudal': {'pos': '0', 'neg': '0'},\n",
       " 'retral': {'pos': '0', 'neg': '0'},\n",
       " 'dorsoventral': {'pos': '0', 'neg': '0'},\n",
       " 'appealable': {'pos': '0.5', 'neg': '0'},\n",
       " 'unappealable': {'pos': '0', 'neg': '0.5'},\n",
       " 'appendaged': {'pos': '0', 'neg': '0'},\n",
       " 'unappendaged': {'pos': '0', 'neg': '0.625'},\n",
       " 'appetizing': {'pos': '0.5', 'neg': '0.25'},\n",
       " 'savoury': {'pos': '0.125', 'neg': '0'},\n",
       " 'unappetizing': {'pos': '0', 'neg': '0.75'},\n",
       " 'approachable': {'pos': '0.625', 'neg': '0'},\n",
       " 'unapproachable': {'pos': '0', 'neg': '0.375'},\n",
       " 'standoffish': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'appropriate': {'pos': '0', 'neg': '0'},\n",
       " 'befitting': {'pos': '0', 'neg': '0'},\n",
       " 'grade-appropriate': {'pos': '0', 'neg': '0'},\n",
       " 'pat': {'pos': '0', 'neg': '0'},\n",
       " 'right': {'pos': '0', 'neg': '0.125'},\n",
       " 'inappropriate': {'pos': '0.125', 'neg': '0.75'},\n",
       " 'unbefitting': {'pos': '0', 'neg': '0.625'},\n",
       " 'due': {'pos': '0', 'neg': '0'},\n",
       " 'callable': {'pos': '0', 'neg': '0'},\n",
       " 'collect': {'pos': '0', 'neg': '0'},\n",
       " 'payable': {'pos': '0.125', 'neg': '0'},\n",
       " 'overdue': {'pos': '0', 'neg': '0.25'},\n",
       " 'receivable': {'pos': '0', 'neg': '0'},\n",
       " 'out-of-pocket': {'pos': '0', 'neg': '0'},\n",
       " 'repayable': {'pos': '0', 'neg': '0'},\n",
       " 'undue': {'pos': '0', 'neg': '0.625'},\n",
       " 'apropos': {'pos': '0.5', 'neg': '0.125'},\n",
       " 'pertinent': {'pos': '0.375', 'neg': '0'},\n",
       " 'malapropos': {'pos': '0', 'neg': '0'},\n",
       " 'out_of_place': {'pos': '0', 'neg': '0'},\n",
       " 'a_priori': {'pos': '0', 'neg': '0'},\n",
       " 'a_posteriori': {'pos': '0', 'neg': '0'},\n",
       " 'apteral': {'pos': '0', 'neg': '0.5'},\n",
       " 'porticoed': {'pos': '0.375', 'neg': '0'},\n",
       " 'pseudoprostyle': {'pos': '0.375', 'neg': '0'},\n",
       " 'peripteral': {'pos': '0', 'neg': '0'},\n",
       " 'monopteral': {'pos': '0', 'neg': '0'},\n",
       " 'pseudoperipteral': {'pos': '0', 'neg': '0'},\n",
       " 'arbitrable': {'pos': '0', 'neg': '0'},\n",
       " 'nonarbitrable': {'pos': '0', 'neg': '0.625'},\n",
       " 'columned': {'pos': '0.125', 'neg': '0'},\n",
       " 'amphistylar': {'pos': '0', 'neg': '0'},\n",
       " 'columnar': {'pos': '0.375', 'neg': '0.25'},\n",
       " 'columnlike': {'pos': '0', 'neg': '0'},\n",
       " 'colonnaded': {'pos': '0.125', 'neg': '0'},\n",
       " 'pillared': {'pos': '0.125', 'neg': '0'},\n",
       " 'uncolumned': {'pos': '0', 'neg': '0.5'},\n",
       " 'astylar': {'pos': '0', 'neg': '0.25'},\n",
       " 'unpillared': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'tree-living': {'pos': '0', 'neg': '0'},\n",
       " 'nonarboreal': {'pos': '0', 'neg': '0.625'},\n",
       " 'sandy': {'pos': '0', 'neg': '0'},\n",
       " 'clayey': {'pos': '0', 'neg': '0.125'},\n",
       " 'armed': {'pos': '0', 'neg': '0'},\n",
       " 'weaponed': {'pos': '0', 'neg': '0'},\n",
       " 'light-armed': {'pos': '0', 'neg': '0'},\n",
       " 'militarized': {'pos': '0', 'neg': '0'},\n",
       " 'unarmed': {'pos': '0', 'neg': '0.625'},\n",
       " 'barehanded': {'pos': '0.125', 'neg': '0'},\n",
       " 'defenseless': {'pos': '0', 'neg': '0.25'},\n",
       " 'weaponless': {'pos': '0', 'neg': '0'},\n",
       " 'armoured': {'pos': '0', 'neg': '0.125'},\n",
       " 'steel-plated': {'pos': '0', 'neg': '0.375'},\n",
       " 'bony-plated': {'pos': '0', 'neg': '0.5'},\n",
       " 'bulletproof': {'pos': '0', 'neg': '0'},\n",
       " 'lightly_armoured': {'pos': '0', 'neg': '0'},\n",
       " 'mail-cheeked': {'pos': '0', 'neg': '0'},\n",
       " 'mailed': {'pos': '0', 'neg': '0.125'},\n",
       " 'scaled': {'pos': '0', 'neg': '0'},\n",
       " 'unarmoured': {'pos': '0', 'neg': '0.125'},\n",
       " 'thorny': {'pos': '0', 'neg': '0.875'},\n",
       " 'bristlelike': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'brushlike': {'pos': '0', 'neg': '0.125'},\n",
       " 'thistlelike': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'taloned': {'pos': '0', 'neg': '0.25'},\n",
       " 'thornless': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'armlike': {'pos': '0', 'neg': '0.125'},\n",
       " 'brachiate': {'pos': '0', 'neg': '0'},\n",
       " 'long-armed': {'pos': '0', 'neg': '0'},\n",
       " 'one-armed': {'pos': '0', 'neg': '0'},\n",
       " 'armless': {'pos': '0', 'neg': '0'},\n",
       " 'bone-covered': {'pos': '0', 'neg': '0.125'},\n",
       " 'scaly': {'pos': '0', 'neg': '0'},\n",
       " 'silver-scaled': {'pos': '0', 'neg': '0'},\n",
       " 'scaleless': {'pos': '0', 'neg': '0.625'},\n",
       " 'artful': {'pos': '0.625', 'neg': '0'},\n",
       " 'wily': {'pos': '0.625', 'neg': '0.125'},\n",
       " 'precious': {'pos': '0.5', 'neg': '0'},\n",
       " 'scheming': {'pos': '0.125', 'neg': '0'},\n",
       " 'deep': {'pos': '0', 'neg': '0'},\n",
       " 'elusive': {'pos': '0', 'neg': '0.625'},\n",
       " 'manipulative': {'pos': '0.25', 'neg': '0'},\n",
       " 'pawky': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'artless': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'careless': {'pos': '0', 'neg': '0.5'},\n",
       " 'articulate': {'pos': '0', 'neg': '0'},\n",
       " 'smooth-spoken': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'speech-endowed': {'pos': '0.5', 'neg': '0'},\n",
       " 'well-spoken': {'pos': '0', 'neg': '0'},\n",
       " 'unarticulate': {'pos': '0', 'neg': '0.625'},\n",
       " 'aphasic': {'pos': '0', 'neg': '0.75'},\n",
       " 'voiceless': {'pos': '0', 'neg': '0'},\n",
       " 'silent': {'pos': '0', 'neg': '0'},\n",
       " 'dumb': {'pos': '0', 'neg': '0'},\n",
       " 'tongue-tied': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'wordless': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'speechless': {'pos': '0', 'neg': '0.625'},\n",
       " 'unarticulated': {'pos': '0', 'neg': '0.625'},\n",
       " 'speaking': {'pos': '0.5', 'neg': '0'},\n",
       " 'tongued': {'pos': '0', 'neg': '0.375'},\n",
       " 'walk-on': {'pos': '0', 'neg': '0'},\n",
       " 'articulated': {'pos': '0', 'neg': '0.625'},\n",
       " 'jointed': {'pos': '0', 'neg': '0'},\n",
       " 'unjointed': {'pos': '0', 'neg': '0.5'},\n",
       " 'ashamed': {'pos': '0', 'neg': '0.75'},\n",
       " 'shamed': {'pos': '0', 'neg': '0.5'},\n",
       " 'mortified': {'pos': '0', 'neg': '0.5'},\n",
       " 'shamefaced': {'pos': '0.5', 'neg': '0.5'},\n",
       " 'sheepish': {'pos': '0.5', 'neg': '0.25'},\n",
       " 'unashamed': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'insolent': {'pos': '0.75', 'neg': '0.125'},\n",
       " 'unblushing': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'unembarrassed': {'pos': '0', 'neg': '0.375'},\n",
       " 'self-assertive': {'pos': '0', 'neg': '0.5'},\n",
       " 'cocky': {'pos': '0.5', 'neg': '0.25'},\n",
       " 'forceful': {'pos': '0', 'neg': '0.5'},\n",
       " 'unassertive': {'pos': '0.625', 'neg': '0'},\n",
       " 'nonassertive': {'pos': '0.25', 'neg': '0.375'},\n",
       " 'self-effacing': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'associatory': {'pos': '0', 'neg': '0.625'},\n",
       " 'associable': {'pos': '0.625', 'neg': '0'},\n",
       " 'nonassociative': {'pos': '0', 'neg': '0.125'},\n",
       " 'committed': {'pos': '0', 'neg': '0'},\n",
       " 'betrothed': {'pos': '0', 'neg': '0'},\n",
       " 'intended': {'pos': '0', 'neg': '0'},\n",
       " 'involved': {'pos': '0', 'neg': '0'},\n",
       " 'uncommitted': {'pos': '0', 'neg': '0'},\n",
       " 'unpromised': {'pos': '0', 'neg': '0.625'},\n",
       " 'affixed': {'pos': '0.125', 'neg': '0'},\n",
       " 'appendant': {'pos': '0', 'neg': '0'},\n",
       " 'basifixed': {'pos': '0', 'neg': '0'},\n",
       " 'pasted': {'pos': '0', 'neg': '0'},\n",
       " 'unaffixed': {'pos': '0', 'neg': '0.25'},\n",
       " 'stalkless': {'pos': '0', 'neg': '0.125'},\n",
       " 'stalked': {'pos': '0', 'neg': '0.125'},\n",
       " 'sessile': {'pos': '0', 'neg': '0.625'},\n",
       " 'vagile': {'pos': '0', 'neg': '0'},\n",
       " 'unattached': {'pos': '0', 'neg': '0'},\n",
       " 'attached': {'pos': '0', 'neg': '0'},\n",
       " 'detached': {'pos': '0', 'neg': '0'},\n",
       " 'separate': {'pos': '0', 'neg': '0'},\n",
       " 'semidetached': {'pos': '0', 'neg': '0'},\n",
       " 'stuck': {'pos': '0', 'neg': '0'},\n",
       " 'cragfast': {'pos': '0', 'neg': '0'},\n",
       " 'unstuck': {'pos': '0', 'neg': '0'},\n",
       " 'attachable': {'pos': '0.5', 'neg': '0'},\n",
       " 'clip-on': {'pos': '0', 'neg': '0'},\n",
       " 'tie-on': {'pos': '0', 'neg': '0'},\n",
       " 'detachable': {'pos': '0.25', 'neg': '0'},\n",
       " 'clastic': {'pos': '0', 'neg': '0'},\n",
       " 'wary': {'pos': '0', 'neg': '0.625'},\n",
       " \"upon_one's_guard\": {'pos': '0.375', 'neg': '0'},\n",
       " 'shy': {'pos': '0', 'neg': '0'},\n",
       " 'unwary': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'gullible': {'pos': '0.5', 'neg': '0.25'},\n",
       " 'unguarded': {'pos': '0', 'neg': '0.375'},\n",
       " 'attentive': {'pos': '0.25', 'neg': '0'},\n",
       " 'wrapped': {'pos': '0', 'neg': '0'},\n",
       " 'heedful': {'pos': '0.375', 'neg': '0'},\n",
       " 'observant': {'pos': '0.375', 'neg': '0'},\n",
       " 'oversolicitous': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'solicitous': {'pos': '0.125', 'neg': '0.75'},\n",
       " 'inattentive': {'pos': '0.25', 'neg': '0.375'},\n",
       " 'scatty': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'distrait': {'pos': '0', 'neg': '0.25'},\n",
       " 'woolgathering': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'yawning': {'pos': '0', 'neg': '0'},\n",
       " 'oblivious': {'pos': '0.375', 'neg': '0'},\n",
       " 'attractive': {'pos': '0.375', 'neg': '0'},\n",
       " 'fascinating': {'pos': '0.5', 'neg': '0'},\n",
       " 'magnetic': {'pos': '0', 'neg': '0'},\n",
       " 'cute': {'pos': '0.5', 'neg': '0'},\n",
       " 'dinky': {'pos': '0', 'neg': '0'},\n",
       " 'piquant': {'pos': '0.875', 'neg': '0'},\n",
       " 'winning': {'pos': '0.25', 'neg': '0.375'},\n",
       " 'showy': {'pos': '0.5', 'neg': '0'},\n",
       " 'spellbinding': {'pos': '0.375', 'neg': '0'},\n",
       " 'irresistible': {'pos': '0.625', 'neg': '0.125'},\n",
       " 'personable': {'pos': '0.625', 'neg': '0'},\n",
       " 'photogenic': {'pos': '0.5', 'neg': '0'},\n",
       " 'prepossessing': {'pos': '0.5', 'neg': '0'},\n",
       " 'winsome': {'pos': '0.625', 'neg': '0'},\n",
       " 'unattractive': {'pos': '0.375', 'neg': '0'},\n",
       " 'plain': {'pos': '0', 'neg': '0'},\n",
       " 'subfusc': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'unpresentable': {'pos': '0', 'neg': '0.125'},\n",
       " 'repulsive': {'pos': '0', 'neg': '0.75'},\n",
       " 'appealing': {'pos': '0.25', 'neg': '0'},\n",
       " 'catchy': {'pos': '0.25', 'neg': '0'},\n",
       " 'unappealing': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'off-putting': {'pos': '0', 'neg': '0.75'},\n",
       " 'attributable': {'pos': '0.625', 'neg': '0'},\n",
       " 'referable': {'pos': '0', 'neg': '0.25'},\n",
       " 'credited': {'pos': '0', 'neg': '0'},\n",
       " 'traceable': {'pos': '0', 'neg': '0'},\n",
       " 'unattributable': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'prenominal': {'pos': '0', 'neg': '0'},\n",
       " 'attributive_genitive': {'pos': '0', 'neg': '0'},\n",
       " 'predicative': {'pos': '0', 'neg': '0'},\n",
       " 'pregnant': {'pos': '0', 'neg': '0.5'},\n",
       " 'with_child': {'pos': '0', 'neg': '0'},\n",
       " 'nonpregnant': {'pos': '0', 'neg': '0.125'},\n",
       " 'hearable': {'pos': '0.375', 'neg': '0'},\n",
       " 'clunky': {'pos': '0', 'neg': '0'},\n",
       " 'sonic': {'pos': '0', 'neg': '0'},\n",
       " 'sounding': {'pos': '0', 'neg': '0'},\n",
       " 'unhearable': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'infrasonic': {'pos': '0.375', 'neg': '0'},\n",
       " 'unsounded': {'pos': '0.375', 'neg': '0'},\n",
       " 'ultrasonic': {'pos': '0.375', 'neg': '0'},\n",
       " 'unheard': {'pos': '0.25', 'neg': '0'},\n",
       " 'transonic': {'pos': '0', 'neg': '0'},\n",
       " 'subsonic': {'pos': '0', 'neg': '0'},\n",
       " 'supersonic': {'pos': '0', 'neg': '0'},\n",
       " 'auspicious': {'pos': '0.625', 'neg': '0'},\n",
       " 'promising': {'pos': '0.75', 'neg': '0'},\n",
       " 'rosy': {'pos': '0.625', 'neg': '0'},\n",
       " 'unfortunate': {'pos': '0', 'neg': '0.875'},\n",
       " 'unpromising': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'propitious': {'pos': '0.5', 'neg': '0'},\n",
       " 'prosperous': {'pos': '0.5', 'neg': '0.125'},\n",
       " 'gracious': {'pos': '0.625', 'neg': '0.125'},\n",
       " 'unpropitious': {'pos': '0', 'neg': '0.625'},\n",
       " 'ominous': {'pos': '0.25', 'neg': '0.75'},\n",
       " 'thunderous': {'pos': '0.125', 'neg': '0.875'},\n",
       " 'authorized': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'licensed': {'pos': '0', 'neg': '0'},\n",
       " 'sanctioned': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'glorified': {'pos': '0.125', 'neg': '0.125'},\n",
       " 'sceptred': {'pos': '0', 'neg': '0'},\n",
       " 'unauthorized': {'pos': '0', 'neg': '0.875'},\n",
       " 'self-appointed': {'pos': '0', 'neg': '0'},\n",
       " 'unlicensed': {'pos': '0', 'neg': '0.25'},\n",
       " 'constitutional': {'pos': '0', 'neg': '0'},\n",
       " 'unconstitutional': {'pos': '0', 'neg': '0.75'},\n",
       " 'autochthonous': {'pos': '0', 'neg': '0'},\n",
       " 'allochthonous': {'pos': '0', 'neg': '0'},\n",
       " 'homoecious': {'pos': '0', 'neg': '0'},\n",
       " 'heteroecious': {'pos': '0', 'neg': '0'},\n",
       " 'autogenous': {'pos': '0', 'neg': '0'},\n",
       " 'self-produced': {'pos': '0', 'neg': '0'},\n",
       " 'self-induced': {'pos': '0.375', 'neg': '0.125'},\n",
       " 'heterogenous': {'pos': '0', 'neg': '0.625'},\n",
       " 'automatic': {'pos': '0', 'neg': '0'},\n",
       " 'semiautomatic': {'pos': '0', 'neg': '0'},\n",
       " 'machine-driven': {'pos': '0', 'neg': '0'},\n",
       " 'self-regulating': {'pos': '0', 'neg': '0'},\n",
       " 'self-locking': {'pos': '0', 'neg': '0'},\n",
       " 'self-winding': {'pos': '0', 'neg': '0'},\n",
       " 'smart': {'pos': '0', 'neg': '0.375'},\n",
       " 'manual': {'pos': '0', 'neg': '0'},\n",
       " 'non-automatic': {'pos': '0', 'neg': '0'},\n",
       " 'available': {'pos': '0.375', 'neg': '0'},\n",
       " 'acquirable': {'pos': '0.625', 'neg': '0'},\n",
       " 'addressable': {'pos': '0.625', 'neg': '0'},\n",
       " 'forthcoming': {'pos': '0.125', 'neg': '0'},\n",
       " 'procurable': {'pos': '0.625', 'neg': '0'},\n",
       " 'in_stock': {'pos': '0', 'neg': '0'},\n",
       " 'lendable': {'pos': '0.25', 'neg': '0'},\n",
       " 'visible': {'pos': '0.125', 'neg': '0'},\n",
       " 'on_hand': {'pos': '0.375', 'neg': '0'},\n",
       " 'on_tap': {'pos': '0', 'neg': '0'},\n",
       " 'purchasable': {'pos': '0', 'neg': '0'},\n",
       " 'ready': {'pos': '0', 'neg': '0'},\n",
       " 'unavailable': {'pos': '0.375', 'neg': '0.5'},\n",
       " 'untouchable': {'pos': '0', 'neg': '0'},\n",
       " 'out_of_stock': {'pos': '0', 'neg': '0.625'},\n",
       " 'awake': {'pos': '0.625', 'neg': '0'},\n",
       " 'up': {'pos': '0', 'neg': '0'},\n",
       " 'awakened': {'pos': '0', 'neg': '0'},\n",
       " 'waking': {'pos': '0', 'neg': '0'},\n",
       " 'asleep': {'pos': '0', 'neg': '0'},\n",
       " 'at_rest': {'pos': '0', 'neg': '0'},\n",
       " 'drowsy': {'pos': '0', 'neg': '0'},\n",
       " 'sound_asleep': {'pos': '0', 'neg': '0.125'},\n",
       " 'hypnoid': {'pos': '0', 'neg': '0'},\n",
       " 'sleepyheaded': {'pos': '0', 'neg': '0'},\n",
       " 'somnolent': {'pos': '0.5', 'neg': '0.125'},\n",
       " 'unawakened': {'pos': '0', 'neg': '0.625'},\n",
       " 'astringent': {'pos': '0.125', 'neg': '0.375'},\n",
       " 'styptic': {'pos': '0', 'neg': '0'},\n",
       " 'nonastringent': {'pos': '0', 'neg': '0.375'},\n",
       " 'cognizant': {'pos': '0.5', 'neg': '0'},\n",
       " 'conscious': {'pos': '0.375', 'neg': '0'},\n",
       " 'sensible': {'pos': '0.5', 'neg': '0'},\n",
       " 'unaware': {'pos': '0', 'neg': '0.25'},\n",
       " 'unmindful': {'pos': '0.125', 'neg': '0.75'},\n",
       " 'unconscious': {'pos': '0', 'neg': '0.25'},\n",
       " 'unsuspecting': {'pos': '0', 'neg': '0.625'},\n",
       " 'witting': {'pos': '0.125', 'neg': '0.25'},\n",
       " 'unwitting': {'pos': '0', 'neg': '0.25'},\n",
       " 'alarming': {'pos': '0', 'neg': '0.5'},\n",
       " 'dismaying': {'pos': '0', 'neg': '0.5'},\n",
       " 'ugly': {'pos': '0', 'neg': '0.75'},\n",
       " 'terrible': {'pos': '0', 'neg': '0.625'},\n",
       " 'threatening': {'pos': '0', 'neg': '0'},\n",
       " 'nightmarish': {'pos': '0.25', 'neg': '0.625'},\n",
       " 'shuddery': {'pos': '0', 'neg': '0.75'},\n",
       " 'creepy-crawly': {'pos': '0', 'neg': '0'},\n",
       " 'unnerving': {'pos': '0.625', 'neg': '0'},\n",
       " 'sick': {'pos': '0', 'neg': '0'},\n",
       " 'hairy': {'pos': '0', 'neg': '0.25'},\n",
       " 'petrifying': {'pos': '0', 'neg': '0.25'},\n",
       " 'stupefying': {'pos': '0.125', 'neg': '0.625'},\n",
       " 'terrifying': {'pos': '0', 'neg': '0.625'},\n",
       " 'unalarming': {'pos': '0.25', 'neg': '0.25'},\n",
       " 'anemophilous': {'pos': '0', 'neg': '0'},\n",
       " 'entomophilous': {'pos': '0', 'neg': '0'},\n",
       " 'reassuring': {'pos': '0.5', 'neg': '0'},\n",
       " 'soothing': {'pos': '0.125', 'neg': '0.5'},\n",
       " 'assuring': {'pos': '0.5', 'neg': '0'},\n",
       " 'consoling': {'pos': '0.5', 'neg': '0.5'},\n",
       " 'worrisome': {'pos': '0.25', 'neg': '0.5'},\n",
       " 'back': {'pos': '0', 'neg': '0'},\n",
       " 'rearmost': {'pos': '0', 'neg': '0'},\n",
       " 'rearward': {'pos': '0', 'neg': '0'},\n",
       " 'front': {'pos': '0', 'neg': '0.125'},\n",
       " 'in_advance': {'pos': '0', 'neg': '0'},\n",
       " 'frontmost': {'pos': '0', 'neg': '0'},\n",
       " 'head-on': {'pos': '0', 'neg': '0'},\n",
       " 'leading': {'pos': '0', 'neg': '0'},\n",
       " 'guiding': {'pos': '0', 'neg': '0'},\n",
       " 'following': {'pos': '0', 'neg': '0'},\n",
       " 'pursuing': {'pos': '0', 'neg': '0'},\n",
       " 'backed': {'pos': '0', 'neg': '0'},\n",
       " 'hardcover': {'pos': '0', 'neg': '0'},\n",
       " 'high-backed': {'pos': '0.125', 'neg': '0'},\n",
       " 'low-backed': {'pos': '0', 'neg': '0.125'},\n",
       " 'razorback': {'pos': '0', 'neg': '0'},\n",
       " ...}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis the range of sentiment lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_max = 0\n",
    "pos_min = 0\n",
    "neg_max = 0\n",
    "neg_min = 0\n",
    "for sen in sentiment_dict:\n",
    "    pos = float(sentiment_dict[sen]['pos'])\n",
    "    neg = float(sentiment_dict[sen]['neg'])\n",
    "    if pos>pos_max:\n",
    "        pos_max = pos\n",
    "    elif pos<pos_min:\n",
    "        pos_min = pos\n",
    "    if neg>neg_max:\n",
    "        neg_max = neg\n",
    "    elif neg<neg_min:\n",
    "        neg_min = neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0\n",
      "1.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(pos_max)\n",
    "print(pos_min)\n",
    "print(neg_max)\n",
    "print(neg_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Traversing the original dataset, and compare with the sentiment dictionary. If it is the positive sentiment word,\n",
    "## then increase the value of the word, reversely if it is the negative sentiment word, then decrease the value.\n",
    "## Finally calculate the sentiment value and reflect them into the 5-point scale scores\n",
    "def compute(review):\n",
    "    word_list = review.split(' ')\n",
    "    value = 0\n",
    "    for word in word_list:    ## Adjust sentiment value and calculation method\n",
    "        num = 0\n",
    "        if word in sentiment_dict:\n",
    "            if float(sentiment_dict[word]['pos'])>=float(sentiment_dict[word]['neg']):\n",
    "                value += float(sentiment_dict[word]['pos'])\n",
    "                num += 1\n",
    "            else:\n",
    "                value -= float(sentiment_dict[word]['neg'])\n",
    "                num += 1\n",
    "    if num>0:\n",
    "        value /= num     \n",
    "    return value\n",
    "    #value*=5\n",
    "#     print(value)\n",
    "#     if value>=1:      ## Adjust the threshold for sentiment classification\n",
    "#         return 2\n",
    "#     elif value>=-3:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lexicons_score = [compute(train_x[i]) for i in range(len(train_x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lexicons_score = [compute(test_x[i]) for i in range(len(test_x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig  = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.plot(np.arange(len(train_lexicons_score)),train_lexicons_score)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat lexion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_features = np.hstack([train_features[:,feature_selected[:20]],np.array(train_lexicons_score).reshape(-1,1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_features = np.hstack([test_features[:,feature_selected[:20]],np.array(test_lexicons_score).reshape(-1,1) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_num = 0\n",
    "# total = len(train_y)\n",
    "# for i in range(len(train_y)):\n",
    "#     if pred_labels[i] ==train_y[i]:\n",
    "#         acc_num+=1\n",
    "# print('At sentiment lexicon model，the accurate of training set：', acc_num/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=10,max_depth=None,random_state=1,\n",
    "          n_jobs=13,min_weight_fraction_leaf=0,criterion='gini',\n",
    "          min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning Super parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 0\n",
    "# acc_num = 0\n",
    "# total = len(test_x)\n",
    "# for review in test_x:\n",
    "#     if compute(review)==test_y[num]:\n",
    "#         acc_num+=1\n",
    "#     num += 1\n",
    "# print(total)\n",
    "# print(acc_num)\n",
    "# print('At sentiment lexicon model，the accurate of test set：', acc_num/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "_n_estimators = [10,20,50,100,200]\n",
    "_max_depth = [5,10,15,None]\n",
    "_min_samples_leaf = [1,2,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score 0.6942551119766309 best parameters: 10 5 1\n",
      "The score 0.6962025316455697 best parameters: 10 5 2\n",
      "The score 0.7020447906523856 best parameters: 20 15 1\n"
     ]
    }
   ],
   "source": [
    "_best_score = 0\n",
    "for _n in _n_estimators:\n",
    "    for _s in _max_depth:\n",
    "        for _t in _min_samples_leaf:\n",
    "            clf=RandomForestClassifier(n_estimators=_n,max_depth=_s,random_state=1,\n",
    "              n_jobs=13,min_weight_fraction_leaf=0,criterion='gini',\n",
    "              min_samples_leaf=_t)\n",
    "            clf.fit(train_features[:,feature_selected[:20]] ,train_y)\n",
    "            cur_score = clf.score(test_features[:,feature_selected[:20]],test_y)\n",
    "            if cur_score>_best_score:\n",
    "                _best_score = cur_score\n",
    "                print('The score %s best parameters:'%(_best_score),_n,_s,_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691333982473223\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_features[:,feature_selected[:20]] ,train_y)\n",
    "print(clf.score(test_features[:,feature_selected[:20]],test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('At sentiment lexicon model，the accurate of training set：', clf.score(train_final_features,train_y))\n",
    "#print('At sentiment lexicon model，the accurate of test set：', clf.score(test_final_features,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6864654333008764\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=10,max_depth=None,random_state=1,\n",
    "          n_jobs=13,min_weight_fraction_leaf=0,criterion='gini',\n",
    "          min_samples_leaf=5)\n",
    "clf.fit(train_features[:,feature_selected[:20]] ,train_y)\n",
    "print(clf.score(test_features[:,feature_selected[:20]],test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate of using lexicon：\n",
      "0.691333982473223\n"
     ]
    }
   ],
   "source": [
    "print('The accurate of using lexicon：')\n",
    "clf.fit(train_final_features ,train_y)\n",
    "print(clf.score(test_final_features,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类模型比情感词典的方式更有效，情感字典作为额外特征对最终效果有下降影响，需要考虑进一步算法提升情感字典"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
